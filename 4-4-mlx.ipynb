{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4: 前馈式矩阵乘积态机器学习模型\n",
    "\n",
    "> References:\n",
    "> * [TensorNetwork for Machine Learning](https://arxiv.org/abs/1906.06329)\n",
    "> * [Residual Matrix Product State for Machine Learning](https://arxiv.org/abs/2012.11841)\n",
    ">    * ResMPS 很像 RNN\n",
    "\n",
    "前馈式矩阵乘积态机器学习模型：\n",
    "* 张量可作为从多个向量到单个向量（或张量）的映射\n",
    "* 该映射可作为机器学习映射，其变分参数为张量元\n",
    "\n",
    "步骤：\n",
    "1. 特征映射 - 将各个特征映射为向量，将样本映射为多个向量的直积（与ADQC类似，见第3.4）\n",
    "2. 计算特征向量与张量网络的收缩，获得输出向量\n",
    "\n",
    "结构\n",
    "![tn_machine](./images/tn_machine.png)\n",
    "\n",
    "## 残差 MPS (ResMPS)\n",
    "\n",
    "* 由于MPS长度等于样本特征个数（例如 MNIST 每个样本含784个特征），绝大部分矩阵乘积态会出现\"**正交灾难**\"（见4.1）\n",
    "* ResMPS：利用\"**残差(residual)**\"的思想来避免正交灾难的发生\n",
    "\n",
    "### 收缩算法\n",
    "\n",
    "![res_mps_contraction](./images/res_mps_contraction.png)\n",
    "\n",
    "* 从两端到中间（类别指标处）进行收缩，局域收缩表达式为：\n",
    "  $$\\sum_{\\alpha_l s_l} v_{\\alpha_l}^{(l)} \\phi_{s_l}^{(l)} A_{\\alpha_l s_l \\alpha_{l+1}}^{(l)} = v_{\\alpha_{l+1}}^{(l+1)}$$\n",
    "* 向量$v^{(0)} = [1]$， $v^{(L-1)} = [1]$（注：最左侧张量的左虚拟指标维数为1，最右侧张量的右虚拟指标维数为1）\n",
    "* ResMPS 的局域张量满足：$A_{:,0,:}^{(l)} = I$, $|A_{:,1,:}^{(l)}| \\sim \\varepsilon$\n",
    "    * 中间指标的 0 分量是 $I$, 而 1 分量的模长是一个小量\n",
    "* 选取特征映射：$x_l \\rightarrow \\phi^{(l)} = [1, x_l]$\n",
    "\n",
    "> 残差项推导：\n",
    "> \n",
    "> 1. ResMPS的局域张量满足: $A_{:,0,:}^{(l)} = I$, $|A_{:,1,:}^{(l)}| \\sim \\varepsilon$\n",
    "> 2. 选取特征映射: $x_l \\to \\phi^{(l)} = [1, x_l]$\n",
    "> 3. 代入上面的局域收缩表达式得到下面的式子\n",
    "> \n",
    "> $$\\boldsymbol{v}^{(l+1)} = \\boldsymbol{v}^{(l)} + x_l\\boldsymbol{v}^{(l)}A_{:,1,:}^{(l)}$$\n",
    "> \n",
    "> 前半部分是特征和 0 分量（即 $I$ 相乘）得到，后半部分是 1 分量和上一步的 latent 相乘得到的残差项\n",
    "\n",
    "> 证明：残差为微扰项时，可避免“正交灾难”\n",
    ">\n",
    "> 取模得: $|\\boldsymbol{v}^{(l-1)}\\boldsymbol{A}_{:,1,:}^{(l-1)}| \\approx \\varepsilon|\\boldsymbol{v}^{(l-1)}|$\n",
    ">\n",
    "> 代入$\\boldsymbol{v}^{(l)} = \\boldsymbol{v}^{(l-1)} + x_{l-1}\\boldsymbol{v}^{(l-1)}\\boldsymbol{A}_{:,1,:}^{(l-1)}$ 并用三角不等式有:\n",
    ">\n",
    "> $|\\boldsymbol{v}^{(l)}| \\leq (1 + |x_{l-1}|\\varepsilon)|\\boldsymbol{v}^{(l-1)}| \\leq (1 + |x_{l-1}|\\varepsilon)(1 + |x_{l-2}|\\varepsilon)|\\boldsymbol{v}^{(l-2)}|$\n",
    ">\n",
    "> 仅保留到$\\varepsilon$的线性项，有:\n",
    ">\n",
    "> $|\\boldsymbol{v}^{(l)}| \\lesssim [1 + (|x_{l-1}| + |x_{l-2}|)\\varepsilon]|\\boldsymbol{v}^{(l-2)}|$\n",
    ">\n",
    "> 依此类推:\n",
    ">\n",
    "> $|\\boldsymbol{v}^{(l)}| \\lesssim [1 + K\\bar{x}\\varepsilon]|\\boldsymbol{v}^{(l-K)}|$\n",
    "> \n",
    "> 类似地，可以证明 $[1 - K\\bar{x}\\varepsilon]|\\boldsymbol{v}^{(l-K)}| \\lesssim |\\boldsymbol{v}^{(l)}| $\n",
    ">\n",
    "> 即 $\\boldsymbol{v}^{(l)}$ 的模长仅近似地随收缩张量个数$K$线性变化，从而避免了指数地增大或缩小\n",
    "\n",
    "\n",
    "* 实际计算中，可直接处理残差的计算，从而节省计算量\n",
    "* 定义局域张量{$B^{(l)}$}，局域收缩为\n",
    "    $$v_{a_{l+1}}^{(l+1)} = v_{a_l}^{(l)} + \\sum_{a_l s_l} v_{a_l}^{(l)} \\tilde{\\phi}_{s_l}^{(l)} B_{a_l s_l a_{l+1}}^{(l)}$$\n",
    "\n",
    "    $\\tilde{\\phi}^{(l)}$ 可看作是第 $l$ 个特征 $x_l$ 经过特征映射后所得的向量\n",
    "* 考虑多个样本的并行处理，方法仍然是加入标记样本数目的指标，上式相应地变为\n",
    "    $$v_{n a_{l+1}}^{(l+1)} = v_{n a_l}^{(l)} + \\sum_{a_l s_l} v_{n a_l}^{(l)} \\tilde{\\phi}_{n s_l}^{(l)} B_{a_l s_l a_{l+1}}^{(l)}$$\n",
    "    \n",
    "    $\\tilde{\\phi}_{n,:}^{(l)}$ 为第 $n$ 个样本的 $l$ 个特征经过特征映射后所得的向量，指标 $n$ 的维数为样本个数\n",
    "\n",
    "![res_mps_feature_mapping_comparison](./images/res_mps_feature_mapping_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp mlx.networks.res_mps\n",
    "# |export\n",
    "import mlx.core as mx\n",
    "from mlx import nn\n",
    "from einops import einsum\n",
    "from einops.array_api import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 残差项推导验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_l = 3\n",
    "s_l = 5\n",
    "a_l1 = 4\n",
    "\n",
    "x = mx.random.normal([s_l])\n",
    "v = mx.random.normal([a_l])\n",
    "A = mx.random.normal([a_l, s_l, a_l1])\n",
    "\n",
    "result = einsum(x, v, A, \"s_l, a_l, a_l s_l a_l1 -> a_l1\")\n",
    "\n",
    "result1 = 0\n",
    "for i in range(s_l):\n",
    "    result1 = result1 + x[i] * (v.reshape(1, a_l) @ A[:, i, :])\n",
    "\n",
    "result2 = mx.zeros(a_l1)\n",
    "\n",
    "for i in range(a_l1):\n",
    "    result2[i] = mx.inner(A[:, :, i] @ x, v)\n",
    "\n",
    "assert mx.allclose(result, result1)\n",
    "assert mx.allclose(result, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class ResMPSSimple(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        num_features: int,\n",
    "        feature_dim: int,\n",
    "        num_classes: int,\n",
    "        virtual_dim: int,\n",
    "        eps_norm: float = 1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_features > 0, \"num_features must be positive\"\n",
    "        assert num_classes > 0, \"num_classes must be positive\"\n",
    "        assert feature_dim > 0, \"feature_dim must be positive\"\n",
    "        assert virtual_dim > 0, \"virtual_dim must be positive\"\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.virtual_dim = virtual_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.class_idx = num_features // 2\n",
    "        local_tensors = []\n",
    "        dtype = mx.float32\n",
    "        if num_features == 1:\n",
    "            local_tensors.append(\n",
    "                self._make_local_tensor(\n",
    "                    virtual_dim,\n",
    "                    feature_dim,\n",
    "                    virtual_dim,\n",
    "                    num_classes,\n",
    "                    dtype=dtype,\n",
    "                    eps_norm=eps_norm,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            for i in range(num_features):\n",
    "                if i == self.class_idx:\n",
    "                    tensor_shape = (virtual_dim, feature_dim, virtual_dim, num_classes)\n",
    "                else:\n",
    "                    tensor_shape = (virtual_dim, feature_dim, virtual_dim)\n",
    "                local_tensors.append(\n",
    "                    self._make_local_tensor(*tensor_shape, dtype=dtype, eps_norm=eps_norm)\n",
    "                )\n",
    "        self.local_tensors = local_tensors\n",
    "        contract_vector = mx.ones([virtual_dim], dtype=dtype)\n",
    "        contract_vector /= mx.linalg.norm(contract_vector)\n",
    "        self.contract_vector = contract_vector\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_local_tensor(*shape: int, dtype: mx.Dtype, eps_norm: float) -> mx.array:\n",
    "        tensor = mx.random.normal(shape, dtype=dtype)\n",
    "        tensor /= mx.linalg.norm(tensor)\n",
    "        tensor = tensor * eps_norm\n",
    "        return tensor\n",
    "\n",
    "    @mx.compile\n",
    "    def calc(self, features: mx.array) -> mx.array:\n",
    "        batch_size, num_features, feature_dim = features.shape\n",
    "        latent_left = repeat(\n",
    "            mx.stop_gradient(self.contract_vector),\n",
    "            \"virtual_left -> batch virtual_left\",\n",
    "            batch=batch_size,\n",
    "        )\n",
    "        for feature_idx in range(self.class_idx):\n",
    "            latent = einsum(\n",
    "                self.local_tensors[feature_idx],\n",
    "                latent_left,\n",
    "                features[:, feature_idx, :],\n",
    "                \"left feature right, batch left, batch feature -> batch right\",\n",
    "            )\n",
    "            latent_left = latent + latent_left  # residual\n",
    "\n",
    "        latent_right = repeat(\n",
    "            mx.stop_gradient(self.contract_vector),\n",
    "            \"virtual_right -> batch virtual_right\",\n",
    "            batch=batch_size,\n",
    "        )\n",
    "        for feature_idx in range(num_features - 1, self.class_idx, -1):\n",
    "            latent = einsum(\n",
    "                self.local_tensors[feature_idx],\n",
    "                latent_right,\n",
    "                features[:, feature_idx, :],\n",
    "                \"left feature right, batch right, batch feature -> batch left\",\n",
    "            )\n",
    "            latent_right = latent + latent_right  # residual\n",
    "\n",
    "        activation = einsum(\n",
    "            self.local_tensors[self.class_idx],\n",
    "            latent_left,\n",
    "            latent_right,\n",
    "            features[:, self.class_idx, :],\n",
    "            \"left feature right classes, batch left, batch right, batch feature -> batch classes\",\n",
    "        )\n",
    "        return activation\n",
    "\n",
    "    @mx.compile\n",
    "    @staticmethod\n",
    "    def calc(\n",
    "        local_tensors: list[mx.array],\n",
    "        contract_vector: mx.array,\n",
    "        features: mx.array,\n",
    "        class_idx: int,\n",
    "    ) -> mx.array:\n",
    "        batch_size, num_features, _ = features.shape\n",
    "        latent_left = repeat(\n",
    "            mx.stop_gradient(contract_vector),\n",
    "            \"virtual_left -> batch virtual_left\",\n",
    "            batch=batch_size,\n",
    "        )\n",
    "        for feature_idx in range(class_idx):\n",
    "            latent = einsum(\n",
    "                local_tensors[feature_idx],\n",
    "                latent_left,\n",
    "                features[:, feature_idx, :],\n",
    "                \"left feature right, batch left, batch feature -> batch right\",\n",
    "            )\n",
    "            latent_left = latent + latent_left  # residual\n",
    "\n",
    "        latent_right = repeat(\n",
    "            mx.stop_gradient(contract_vector),\n",
    "            \"virtual_right -> batch virtual_right\",\n",
    "            batch=batch_size,\n",
    "        )\n",
    "        for feature_idx in range(num_features - 1, class_idx, -1):\n",
    "            latent = einsum(\n",
    "                local_tensors[feature_idx],\n",
    "                latent_right,\n",
    "                features[:, feature_idx, :],\n",
    "                \"left feature right, batch right, batch feature -> batch left\",\n",
    "            )\n",
    "            latent_right = latent + latent_right  # residual\n",
    "\n",
    "        activation = einsum(\n",
    "            local_tensors[class_idx],\n",
    "            latent_left,\n",
    "            latent_right,\n",
    "            features[:, class_idx, :],\n",
    "            \"left feature right classes, batch left, batch right, batch feature -> batch classes\",\n",
    "        )\n",
    "        return activation\n",
    "\n",
    "    def __call__(self, features: mx.array) -> mx.array:\n",
    "        # features shape: (batch_size, num_features, feature_dim)\n",
    "        _, num_features, feature_dim = features.shape\n",
    "        assert num_features == self.num_features, (\n",
    "            f\"num_features must be equal to {self.num_features}\"\n",
    "        )\n",
    "        assert feature_dim == self.feature_dim, f\"feature_dim must be equal to {self.feature_dim}\"\n",
    "        return self.calc(\n",
    "            self.local_tensors,\n",
    "            self.contract_vector,\n",
    "            features,\n",
    "            self.class_idx,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: export this\n",
    "def linear_mapping(samples: mx.array) -> mx.array:\n",
    "    \"\"\"\n",
    "    Apply linear feature mapping\n",
    "\n",
    "    Args:\n",
    "        samples: Input tensor of shape (batch_size, *)\n",
    "\n",
    "    Returns:\n",
    "        Output tensor of shape (batch_size, *, 2)\n",
    "    \"\"\"\n",
    "    if samples.ndim == 1:\n",
    "        samples = samples.reshape(1, -1)\n",
    "\n",
    "    return mx.stack([samples, 1 - samples], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_network.utils.data import get_fashion_mnist_datasets\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cache_path = os.path.join(cwd, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_trainset, fmnist_testset = get_fashion_mnist_datasets(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = mx.gpu\n",
    "mx.default_stream(device)\n",
    "batch_size = 2000\n",
    "lr = 1e-4\n",
    "epochs = 30\n",
    "\n",
    "feature_dim = 2\n",
    "virtual_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(fmnist_trainset, batch_size, True)\n",
    "test_loader = DataLoader(fmnist_testset, batch_size, False)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResMPSSimple(\n",
    "    num_features=28 * 28,\n",
    "    feature_dim=feature_dim,\n",
    "    num_classes=num_classes,\n",
    "    virtual_dim=virtual_dim,\n",
    "    eps_norm=1e-4,\n",
    ")\n",
    "\n",
    "parameters = model.parameters()\n",
    "mx.eval(parameters)\n",
    "optimizer = optim.Adam(learning_rate=lr)\n",
    "\n",
    "\n",
    "def loss_fn(model: ResMPSSimple, input_data: mx.array, target: mx.array) -> mx.array:\n",
    "    return mx.mean(nn.losses.cross_entropy(model(input_data), target))\n",
    "\n",
    "\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add test accuracy\n",
    "# FIXME: the training speed is too slow\n",
    "losses = mx.zeros([epochs])\n",
    "train_accuracies = mx.zeros([epochs])\n",
    "progress_bar = tqdm(range(epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    # train_acc = MulticlassAccuracy(num_classes=num_classes)\n",
    "    batch_loss = 0.0\n",
    "    num = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        batch_size = data.shape[0]\n",
    "        data = rearrange(data, \"b c h w -> b (c h w)\")\n",
    "        data = mx.array(data.numpy())\n",
    "        data = linear_mapping(data)\n",
    "        target = mx.array(target.numpy())\n",
    "        loss, grads = loss_and_grad_fn(model, data, target)\n",
    "        optimizer.update(model, grads)\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        num += batch_size\n",
    "        batch_loss += loss * batch_size\n",
    "        # train_acc.update(output.detach(), target)\n",
    "    losses[epoch] = batch_loss / num\n",
    "    # train_accuracies[epoch] = train_acc.compute()\n",
    "    progress_bar.set_description(f\"Epoch {epoch} loss: {losses[epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add test accuracy and plots\n",
    "\n",
    "# test_acc = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "# with torch.no_grad():\n",
    "#     for data, target in tqdm(test_loader):\n",
    "#         batch_size = data.shape[0]\n",
    "#         data = data.to(device)\n",
    "#         data = rearrange(data, \"b c h w -> b (c h w)\")\n",
    "#         target = target.to(device)\n",
    "#         data = linear_mapping(data)\n",
    "#         output = model(data)\n",
    "#         test_acc.update(output, target)\n",
    "\n",
    "\n",
    "# test_acc = test_acc.compute()\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(epochs), train_accuracies.cpu(), label=\"Train Accuracy\")\n",
    "# plt.axhline(y=test_acc.cpu(), color=\"r\", linestyle=\"--\", label=\"Test Accuracy\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training and Test Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(epochs), losses.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
