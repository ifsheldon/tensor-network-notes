# AUTOGENERATED! DO NOT EDIT! File to edit: ../1-6.ipynb.

# %% auto 0
__all__ = ['rand_hermitian_matrix', 'rand_real_symmetric_matrix', 'eigs_power']

# %% ../1-6.ipynb 0
import torch
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
from typing import Tuple

# %% ../1-6.ipynb 2
def rand_hermitian_matrix(dim: int) -> torch.Tensor:
    """
    Generate a random Hermitian matrix of given dimension.

    Args:
        dim (int): Dimension of the matrix.
    Returns:
        torch.Tensor: A Hermitian matrix of the specified dimension.
    """
    H = torch.randn(dim, dim, dtype=torch.complex64)
    H = H + H.conj().t()
    return H


# |export
def rand_real_symmetric_matrix(dim: int) -> torch.Tensor:
    """
    Generate a random real symmetric matrix of given dimension.

    Args:
        dim (int): Dimension of the matrix.
    Returns:
        torch.Tensor: A real symmetric matrix of the specified dimension.
    """
    mat = torch.randn(dim, dim, dtype=torch.float32)
    mat = (mat + mat.t()) / 2
    return mat

# %% ../1-6.ipynb 15
def eigs_power(mat: torch.Tensor, which: str, v0=None) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    ‘LM’ : Largest (in magnitude) eigenvalues.
    ‘SM’ : Smallest (in magnitude) eigenvalues.
    ‘LA’ : Largest (algebraic) eigenvalues.
    ‘SA’ : Smallest (algebraic) eigenvalues.

    Args:
        mat (torch.Tensor): Input matrix (real symmetric).
        which (str): Which eigenvalue to compute ('la', 'sa', 'lm', 'sm').
        v0 (torch.Tensor, optional): Initial vector. If None, a random vector is generated.
    Returns:
        (torch.Tensor, torch.Tensor): The computed eigenvalue and corresponding eigenvector.
    """
    which = which.lower()
    H = mat
    assert which in ["la", "sa", "lm", "sm"]
    assert H.allclose(H.t())
    assert len(H.shape) == 2

    TAU = 0.01
    if which == "la":
        rho = torch.matrix_exp(TAU * H)
    elif which == "lm":
        rho = torch.matrix_exp(TAU * torch.matrix_power(H, 2))
    elif which == "sa":
        rho = torch.matrix_exp(-TAU * H)
    elif which == "sm":
        rho = torch.matrix_exp(-TAU * torch.matrix_power(H, 2))
    else:
        raise NotImplementedError()

    ITER_NUM = 2000
    TOLERANCE = 1e-14
    if v0 is None:
        v = torch.randn(H.shape[1], dtype=H.dtype)
        v = v / v.norm()
    else:
        v = v0

    norm = 1.0
    for _ in tqdm(range(ITER_NUM)):
        v_next = rho @ v
        norm = v_next.norm()
        v_next /= norm
        diff = (v_next - v).norm()
        if diff < TOLERANCE:
            break
        v = v_next

    scaled_eigenvector = H.matmul(v)  # eigenvalue * eigenvector
    # correct sign due to squaring
    sign = torch.sign(v.dot(scaled_eigenvector))

    eigenvector = scaled_eigenvector / scaled_eigenvector.norm()
    if which == "la":
        eigenvalue = torch.log(norm) / TAU
        # same as `scaled_eigenvector.norm()`
        return eigenvalue, eigenvector
    elif which == "sa":
        eigenvalue = -torch.log(norm) / TAU
        # same as `scaled_eigenvector.norm()`
        return eigenvalue, eigenvector
    elif which == "lm":
        eigenvalue = sign * torch.sqrt(torch.log(norm) / TAU)
        # same as `sign * scaled_eigenvector.norm()`
        return eigenvalue, eigenvector
    elif which == "sm":
        # same as `sign * scaled_eigenvector.norm()`
        eigenvalue = sign * torch.sqrt(-torch.log(norm) / TAU)
        return eigenvalue, eigenvector
