# AUTOGENERATED! DO NOT EDIT! File to edit: ../2-5.ipynb.

# %% auto 0
__all__ = ['apply_gate']

# %% ../2-5.ipynb 3
from .utils import iterable_have_common, inverse_permutation, check_quantum_gate, check_state_tensor, unify_tensor_dtypes
import torch
from typing import List
from einops import einsum

# %% ../2-5.ipynb 4
def apply_gate(*, quantum_state: torch.Tensor, gate: torch.Tensor, target_qubit: int | List[int], control_qubit: int | List[int] | None = None) -> torch.Tensor:
    check_state_tensor(quantum_state)

    # check types
    assert isinstance(target_qubit, (int, list)), "target qubit must be int or list"
    assert control_qubit is None or isinstance(control_qubit, (int, list)), "control_qubit must be int or list"


    # unify types
    if isinstance(target_qubit, int):
        target_qubit = [target_qubit]
    if control_qubit is None:
        control_qubit = []
    elif isinstance(control_qubit, int):
        control_qubit = [control_qubit]
    assert not iterable_have_common(target_qubit, control_qubit), "target qubit and control qubit must not overlap"

    num_qubits = quantum_state.ndim
    num_target_qubit = len(target_qubit)
    check_quantum_gate(gate, num_target_qubit)

    quantum_state, gate = unify_tensor_dtypes(quantum_state, gate)

    # check indices
    for qidx in target_qubit:
        assert 0 <= qidx < num_qubits, f"target qubit index {qidx} out of range"
    for qidx in control_qubit:
        assert 0 <= qidx < num_qubits, f"control qubit index {qidx} out of range"    
    
    if gate.ndim == 2:
        # if in matrix form, reshape to tensor form
        new_shape = [2] * (num_target_qubit * 2)
        gate = gate.reshape(new_shape)
    
    other_qubits = list(range(num_qubits))
    for qubit_idx in target_qubit:
        other_qubits.remove(qubit_idx)
    for qubit_idx in control_qubit:
        other_qubits.remove(qubit_idx)

    num_other_qubits = len(other_qubits)
    permutation = target_qubit + other_qubits + control_qubit
    state = torch.permute(quantum_state, permutation)
    state_shape = state.shape # (*target_qubit_shapes, *other_qubit_shapes, *control_qubit_shapes)
    # Flatten the state tensor, so that the shape is (target_qubit_shapes, other_qubit_shapes, -1)
    new_shape = [2] * (num_target_qubit + num_other_qubits) + [-1]
    state = state.reshape(new_shape)
    # only when control qubits are 11111... the gate is applied
    unaffected_state = state[..., :-1] # (*target_qubit_shapes, *other_qubit_shapes, flattened_dim-1)
    state_to_apply_gate = state[..., -1] # (*target_qubit_shapes, *other_qubit_shapes)
    # apply gate
    target_qubit_names = [f"t{i}" for i in target_qubit]
    other_qubit_names = [f"o{i}" for i in other_qubits]
    gate_output_qubit_names = [f"g{i}" for i in target_qubit]
    einsum_str = "{gate_dims}, {state_dims} -> {output_dims}".format(
        gate_dims = " ".join(gate_output_qubit_names + target_qubit_names),
        state_dims = " ".join(target_qubit_names + other_qubit_names),
        output_dims = " ".join(gate_output_qubit_names + other_qubit_names)
    )
    new_state = einsum(gate, state_to_apply_gate, einsum_str)
    new_state = new_state.unsqueeze(-1)

    final_state = torch.cat([unaffected_state, new_state], dim=-1) # (*target_qubit_shapes, *other_qubit_shapes, flattened_dim)
    final_state = final_state.reshape(state_shape) # (*target_qubit_shapes, *other_qubit_shapes, *control_qubit_shapes)
    inversed_permutation = inverse_permutation(permutation)
    final_state = final_state.permute(inversed_permutation)
    return final_state

