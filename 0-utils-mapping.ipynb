{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bd4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp utils.mapping\n",
    "# |export\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "from tensor_network.utils.checking import check_quantum_gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a713a",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89326094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def inverse_permutation(permutation: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Inverse a permutation.\n",
    "    Args:\n",
    "        permutation: The permutation to inverse.\n",
    "    Returns:\n",
    "        The inverse permutation.\n",
    "    \"\"\"\n",
    "    permutation = torch.tensor(permutation, dtype=torch.long)\n",
    "    inv = torch.empty_like(permutation)\n",
    "    inv[permutation] = torch.arange(permutation.size(0))\n",
    "    return inv.tolist()\n",
    "\n",
    "\n",
    "def unify_tensor_dtypes(t1: torch.Tensor, t2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Unify the dtypes of two tensors to the most appropriate type.\n",
    "    Args:\n",
    "        t1: First tensor.\n",
    "        t2: Second tensor.\n",
    "    Returns:\n",
    "        Tuple of tensors with unified dtypes.\n",
    "    Raises:\n",
    "        AssertionError: if the dtypes of the tensors are not valid.\n",
    "    \"\"\"\n",
    "    assert t1.dtype in [torch.float32, torch.float64, torch.complex64, torch.complex128], (\n",
    "        \"quantum_state must be a float or complex tensor\"\n",
    "    )\n",
    "    assert t2.dtype in [torch.float32, torch.float64, torch.complex64, torch.complex128], (\n",
    "        \"quantum_state must be a float or complex tensor\"\n",
    "    )\n",
    "    if t1.dtype == t2.dtype:\n",
    "        return t1, t2\n",
    "    convert_dtypes = [\n",
    "        (torch.float32, torch.complex64, torch.complex64),\n",
    "        (torch.float64, torch.complex64, torch.complex128),\n",
    "        (torch.float32, torch.complex128, torch.complex128),\n",
    "        (torch.float64, torch.complex128, torch.complex128),\n",
    "    ]\n",
    "    for d1, d2, td in convert_dtypes:\n",
    "        if (t1.dtype == d1 and t2.dtype == d2) or (t1.dtype == d2 and t2.dtype == d1):\n",
    "            return t1.to(td), t2.to(td)\n",
    "    raise_dtypes = [\n",
    "        (torch.float32, torch.float64),\n",
    "        (torch.complex64, torch.complex128),\n",
    "    ]\n",
    "    for d1, d2 in raise_dtypes:\n",
    "        if (t1.dtype == d1 and t2.dtype == d2) or (t1.dtype == d2 and t2.dtype == d1):\n",
    "            return t1.to(d2), t2.to(d2)\n",
    "\n",
    "    raise Exception(\"Unreachable code in unify_tensor_dtypes\")\n",
    "\n",
    "\n",
    "def map_float_to_complex(\n",
    "    *, tensor: torch.Tensor | None = None, dtype: torch.dtype | None = None\n",
    ") -> torch.Tensor | torch.dtype:\n",
    "    \"\"\"\n",
    "    Map a float tensor or dtype to a complex tensor or dtype.\n",
    "    Args:\n",
    "        tensor: The input tensor.\n",
    "        dtype: The input dtype.\n",
    "    Returns:\n",
    "        The complex tensor or dtype.\n",
    "    Raises:\n",
    "        AssertionError: If neither tensor nor dtype is provided.\n",
    "    \"\"\"\n",
    "    assert tensor is not None or dtype is not None, \"Either tensor or dtype must be provided\"\n",
    "    original_dtype = tensor.dtype if tensor is not None else dtype\n",
    "    assert original_dtype in [torch.float32, torch.float64], \"dtype must be float32 or float64\"\n",
    "    to_dtype = torch.complex64 if original_dtype == torch.float32 else torch.complex128\n",
    "    if tensor is not None:\n",
    "        return tensor.to(to_dtype)\n",
    "    return to_dtype\n",
    "\n",
    "\n",
    "def view_gate_tensor_as_matrix(\n",
    "    tensor: torch.Tensor, *, num_qubit: int | None = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a tensor representing a quantum gate into a matrix form.\n",
    "    The tensor should have an even number of dimensions, each of size 2.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The tensor representing the quantum gate.\n",
    "        num_qubit (int | None): The number of qubits the gate is acting on. If None, it is inferred from the tensor shape.\n",
    "    Returns:\n",
    "        torch.Tensor: The matrix form of the quantum gate tensor.\n",
    "    \"\"\"\n",
    "    assert tensor.ndim % 2 == 0, \"Tensor must have an even number of dimensions\"\n",
    "    assert all(d == 2 for d in tensor.shape), \"Tensor dimensions must be 2\"\n",
    "    qubit_count = tensor.ndim // 2 if num_qubit is None else num_qubit\n",
    "    check_quantum_gate(tensor, qubit_count)\n",
    "    return tensor.view(2**qubit_count, 2**qubit_count)\n",
    "\n",
    "\n",
    "def view_gate_matrix_as_tensor(\n",
    "    tensor: torch.Tensor, *, num_qubit: int | None = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a matrix representing a quantum gate into a tensor form.\n",
    "    The matrix should have dimensions (2^n, 2^n) for some n.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The matrix representing the quantum gate.\n",
    "        num_qubit (int | None): The number of qubits the gate is acting on. If None, it is inferred from the matrix shape.\n",
    "    Returns:\n",
    "        torch.Tensor: The tensor form of the quantum gate matrix.\n",
    "    \"\"\"\n",
    "    assert tensor.ndim == 2, \"Matrix must have 2 dimensions\"\n",
    "    assert tensor.shape[0] == tensor.shape[1], \"Matrix must be square\"\n",
    "    qubit_count = int(tensor.shape[0].bit_length() - 1) if num_qubit is None else num_qubit\n",
    "    assert tensor.shape[0] == 2**qubit_count, (\n",
    "        f\"Matrix size must be (2^q, 2^q) for q qubits, but got {tensor.shape}\"\n",
    "    )\n",
    "    check_quantum_gate(tensor, qubit_count)\n",
    "    return tensor.view(*([2] * (qubit_count * 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unify_tensor_dtypes\n",
    "for d1 in [torch.float32, torch.float64, torch.complex64, torch.complex128]:\n",
    "    t1 = torch.tensor([1, 2], dtype=d1)\n",
    "    for d2 in [torch.float32, torch.float64, torch.complex64, torch.complex128]:\n",
    "        t2 = torch.tensor([1, 2], dtype=d2)\n",
    "        unify_tensor_dtypes(t1, t2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
