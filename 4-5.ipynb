{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5: 生成式张量网络机器学习及优化算法\n",
    "\n",
    "**ResMPS** : 将张量网络 (MPS) 看作从多个向量到单个向量 (或张量) 的映射，实现分类等预测；\n",
    "\n",
    "**生成式MPS** (generative MPS, 简称GMPS) : 由MPS给出样本的概率分布，实现生成任务。\n",
    "\n",
    "> 核心是波恩概率诠释，见 [2.1](2-1.ipynb)\n",
    "\n",
    "GMPS：将样本出现的概率定义为对该样本进行特征映射后所得量子态与MPS态$|\\phi\\rangle$内积的模方\n",
    "\n",
    "将\"0\"（例如一个白色像素）映射为$|0\\rangle$，将\"1\"（例如一个黑色像素）映射为$|1\\rangle$，则样本\"10101\"被映射为直积态$|10101\\rangle$。对于给定量子态$|\\phi\\rangle$，我们设其为矩阵乘积态，则样本\"10101\"在$|\\phi\\rangle$中出现的概率满足\n",
    "\n",
    "$$p(\\text{\"10101\"}) = \\frac{|\\langle10101|\\phi\\rangle|^2}{\\langle\\phi|\\phi\\rangle}$$\n",
    "\n",
    "![gmps_example](./images/gmps_example.png)\n",
    "\n",
    "> 量子概率性机器学习模型又被称为波恩机\n",
    "\n",
    "## GMPS 训练\n",
    "\n",
    "核心任务：为在保持其量子概率诠释的前提下优化局域张量，使得NLL函数极小\n",
    "\n",
    "损失函数：负对数似然（negative logarithmic likelihood，简称NLL）；\n",
    "\n",
    "在目标概率分布为等概率分布时，NLL与交叉熵（见第三章第3节）仅相差一个常数。\n",
    "\n",
    "具体而言：计算矩阵乘积态对于某个数据集中所有样本的概率分布，并训练矩阵乘积态（即优化局域张量），使得各个样本在矩阵乘积态中出现的概率接近其在数据集中出现的概率。一般而言，各个样本在数据集出现的次数为1，因此，我们需要优化局域张量，使得矩阵乘积态给出的各个样本的概率相等。\n",
    "\n",
    "> NLL函数定义：\n",
    "> \n",
    "> $$f = -\\frac{1}{M}\\sum_{m=0}^{M-1}\\ln\\frac{|\\langle\\phi^{(m)}|\\phi\\rangle|^2}{(\\phi|\\phi)} = -\\frac{1}{M}\\sum_{m=0}^{M-1}[\\ln|\\langle\\phi^{(m)}|\\phi\\rangle|^2-\\ln(\\phi|\\phi)]$$\n",
    "\n",
    "Reference:\n",
    "* [Supervised Learning with Tensor Networks](https://papers.nips.cc/paper_files/paper/2016/hash/5314b9674c86e3f9d1ba25ef9bb32895-Abstract.html)\n",
    "\n",
    "### 张量网络的梯度计算\n",
    "TODO: Add Figure\n",
    "\n",
    "例子：\n",
    "![tensor_network_gradient_calculation_example](./images/tensor_network_gradient_calculation_example.png)\n",
    "\n",
    "> * 梯度的第一项对应于 NLL 的第二项，梯度的第二项对应于 NLL 的第一项，因为合并了最前面的负号\n",
    "> * 梯度第一项的形式需要中心正交形式，例子里的 MPS 的中心必须是在第 2 号局域张量\n",
    "\n",
    "计算的时候可以从两端向正交中心迭代计算，好处是梯度计算公式的上下部分可以复用部分计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:33:50.809089Z",
     "start_time": "2025-05-13T16:33:50.133633Z"
    }
   },
   "outputs": [],
   "source": [
    "# |default_exp algorithms.gmps\n",
    "# |export\n",
    "import torch\n",
    "from tensor_network.mps.modules import MPS, MPSType\n",
    "from einops import einsum\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:33:52.865784Z",
     "start_time": "2025-05-13T16:33:52.855189Z"
    }
   },
   "outputs": [],
   "source": [
    "# |export\n",
    "EPS = 1e-10\n",
    "\n",
    "\n",
    "# prepare env vectors from left to right\n",
    "def calc_left_to_right_step(\n",
    "    current_tensor: torch.Tensor,\n",
    "    current_env_vector_left: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate one step from left to right of the sweep algorithm\n",
    "    \"\"\"\n",
    "    next_env_vector_left = einsum(\n",
    "        current_env_vector_left,\n",
    "        current_sample,\n",
    "        current_tensor,\n",
    "        \"batch left, batch physical, left physical right -> batch right\",\n",
    "    )\n",
    "    current_norm_factor = next_env_vector_left.norm(dim=1, keepdim=True)\n",
    "    return next_env_vector_left / (current_norm_factor + EPS), current_norm_factor.squeeze(-1)\n",
    "\n",
    "\n",
    "def calc_right_to_left_step(\n",
    "    current_tensor: torch.Tensor,\n",
    "    current_env_vector_right: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate one step from right to left of the sweep algorithm\n",
    "    \"\"\"\n",
    "    next_env_vector_right = einsum(\n",
    "        current_env_vector_right,\n",
    "        current_sample,\n",
    "        current_tensor,\n",
    "        \"batch right, batch physical, left physical right -> batch left\",\n",
    "    )\n",
    "    current_norm_factor = next_env_vector_right.norm(dim=1, keepdim=True)\n",
    "    return next_env_vector_right / (current_norm_factor + EPS), current_norm_factor.squeeze(-1)\n",
    "\n",
    "\n",
    "def calc_nll(norm_factors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the negative log likelihood from the norm factors in a batch\n",
    "    \"\"\"\n",
    "    nll = -2 * torch.log(norm_factors.abs() + EPS).sum(dim=1)  # (batch)\n",
    "    return nll\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def calc_gradient(\n",
    "    env_left_vector: torch.Tensor,\n",
    "    env_right_vector: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    "    current_tensor: torch.Tensor,\n",
    "    enable_tsgo: bool,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the gradient w.r.t. the current tensor\n",
    "    \"\"\"\n",
    "    raw_grad = einsum(\n",
    "        env_left_vector,\n",
    "        current_sample,\n",
    "        env_right_vector,\n",
    "        \"batch left, batch physical, batch right -> batch left physical right\",\n",
    "    )\n",
    "    norm = einsum(\n",
    "        current_tensor,\n",
    "        raw_grad,\n",
    "        \"left physical right, batch left physical right -> batch\",\n",
    "    )\n",
    "    norm += torch.sign(norm) * EPS  # add a small number to avoid division by zero\n",
    "    grad = (raw_grad / norm.view(-1, 1, 1, 1)).mean(dim=0)\n",
    "    grad = 2 * (current_tensor - grad)\n",
    "    grad_shape = grad.shape\n",
    "    assert grad_shape == current_tensor.shape\n",
    "    if enable_tsgo:\n",
    "        grad = grad.flatten()\n",
    "        current_tensor = current_tensor.flatten()\n",
    "        projection = torch.dot(grad, current_tensor) * current_tensor\n",
    "        grad = grad - projection\n",
    "        grad = grad.reshape(grad_shape)\n",
    "\n",
    "    grad /= grad.norm()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def eval_nll(\n",
    "    *,\n",
    "    samples: torch.Tensor,\n",
    "    mps: MPS,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    assert samples.ndim == 3  # (dataset_size, feature_num, feature_dim)\n",
    "    assert mps.center is not None\n",
    "    dataset_size, feature_num, _ = samples.shape\n",
    "    assert feature_num == mps.length\n",
    "    # set default device to device\n",
    "    prev_device = torch.get_default_device()\n",
    "    torch.set_default_device(device)\n",
    "    mps_local_tensors = mps.local_tensors\n",
    "    batch_size = dataset_size  # since we do the init NLL evaluation in one go\n",
    "    env_vectors_left: List[torch.Tensor | None] = [None] * mps.length\n",
    "    left_virtual_dim = mps_local_tensors[0].shape[0]\n",
    "    env_vectors_left[0] = torch.ones(batch_size, left_virtual_dim)\n",
    "    env_vectors_right: List[torch.Tensor | None] = [None] * mps.length\n",
    "    right_virtual_dim = mps_local_tensors[-1].shape[-1]\n",
    "    env_vectors_right[-1] = torch.ones(batch_size, right_virtual_dim)\n",
    "    norm_factors = torch.ones(batch_size, feature_num)\n",
    "\n",
    "    def samples_at(idx):\n",
    "        return samples[:, idx, :]  # (batch, feature_dim)\n",
    "\n",
    "    for idx in range(mps.center):\n",
    "        next_env_vector_left, current_norm_factor = calc_left_to_right_step(\n",
    "            mps_local_tensors[idx],\n",
    "            env_vectors_left[idx],\n",
    "            samples_at(idx),\n",
    "        )\n",
    "        # set the norm factor for current position to be the norm of the next env vector, since the next env vector is to be normalized\n",
    "        norm_factors[:, idx] = current_norm_factor\n",
    "        env_vectors_left[idx + 1] = next_env_vector_left\n",
    "\n",
    "    # prepare env vectors from right to left\n",
    "    for idx in range(mps.length - 1, mps.center, -1):\n",
    "        next_env_vector_right, current_norm_factor = calc_right_to_left_step(\n",
    "            mps_local_tensors[idx],\n",
    "            env_vectors_right[idx],\n",
    "            samples_at(idx),\n",
    "        )\n",
    "        norm_factors[:, idx] = current_norm_factor\n",
    "        env_vectors_right[idx - 1] = next_env_vector_right\n",
    "\n",
    "    # update the norm factor at the center\n",
    "    norm_factors[:, mps.center] = einsum(\n",
    "        mps_local_tensors[mps.center],\n",
    "        env_vectors_left[mps.center],\n",
    "        samples_at(mps.center),\n",
    "        env_vectors_right[mps.center],\n",
    "        \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "    )\n",
    "\n",
    "    nll = calc_nll(norm_factors).mean()\n",
    "    # restore the default device\n",
    "    torch.set_default_device(prev_device)\n",
    "    return nll\n",
    "\n",
    "\n",
    "def train_gmps(\n",
    "    *,\n",
    "    samples: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    mps: MPS,\n",
    "    sweep_times: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    enable_tsgo: bool,\n",
    ") -> Tuple[torch.Tensor, MPS]:\n",
    "    dataset_size = samples.shape[0]\n",
    "    assert dataset_size % batch_size == 0\n",
    "    # prepare mps, normalize first to avoid numerical instability\n",
    "    # mps.normalize_()\n",
    "    mps.center_orthogonalization_(0, mode=\"qr\", normalize=True, check_nan=True)\n",
    "    init_nll = eval_nll(samples=samples, mps=mps, device=device)\n",
    "    print(f\"Initially, nll = {init_nll}\")\n",
    "\n",
    "    # set default device to device\n",
    "    prev_device = torch.get_default_device()\n",
    "    torch.set_default_device(device)\n",
    "    # prepare dataloader\n",
    "    dataloader = DataLoader(TensorDataset(samples), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mps_local_tensors = mps._mps  # CAREFUL for inplace operation\n",
    "    feature_num = mps.length\n",
    "    left_virtual_dim = mps_local_tensors[0].shape[0]\n",
    "    right_virtual_dim = mps_local_tensors[-1].shape[-1]\n",
    "\n",
    "    nll_losses = [init_nll]\n",
    "\n",
    "    progress_bar = tqdm(range(sweep_times))\n",
    "    for i in progress_bar:\n",
    "        epoch_nll_losses = []\n",
    "        for batch_data in tqdm(dataloader, leave=False):\n",
    "            batch_data = batch_data[0]\n",
    "            batch_size = batch_data.shape[0]\n",
    "            # prepare aux variables\n",
    "            env_vectors_left: List[torch.Tensor | None] = [None] * mps.length\n",
    "            env_vectors_left[0] = torch.ones(batch_size, left_virtual_dim)\n",
    "            env_vectors_right: List[torch.Tensor | None] = [None] * mps.length\n",
    "            env_vectors_right[-1] = torch.ones(batch_size, right_virtual_dim)\n",
    "            norm_factors = torch.ones(batch_size, feature_num)\n",
    "\n",
    "            def data_at(idx):\n",
    "                return batch_data[:, idx, :]  # (batch, feature_dim)\n",
    "\n",
    "            # prepare env vectors from right to left\n",
    "            # leave out left-to-right because the center of mps always starts at 0\n",
    "            for idx in range(mps.length - 1, mps.center, -1):\n",
    "                next_env_vector_right, current_norm_factor = calc_right_to_left_step(\n",
    "                    mps_local_tensors[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                )\n",
    "                norm_factors[:, idx] = current_norm_factor\n",
    "                env_vectors_right[idx - 1] = next_env_vector_right\n",
    "\n",
    "            # update the norm factor at the center\n",
    "            norm_factors[:, mps.center] = einsum(\n",
    "                mps_local_tensors[mps.center],\n",
    "                env_vectors_left[mps.center],\n",
    "                data_at(mps.center),\n",
    "                env_vectors_right[mps.center],\n",
    "                \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "            )\n",
    "\n",
    "            # gradient calculation and optimization, from left to right\n",
    "            for idx in range(mps.length):\n",
    "                assert idx == mps.center\n",
    "                grad = calc_gradient(\n",
    "                    env_vectors_left[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                    mps_local_tensors[idx],\n",
    "                    enable_tsgo,\n",
    "                )\n",
    "                # update the tensor with gradient, inplace operation, will change mps._mps\n",
    "                mps_local_tensors[idx] -= lr * grad\n",
    "\n",
    "                # prepare for the next iteration\n",
    "                if idx < mps.length - 1:\n",
    "                    # move the center to the right\n",
    "                    # the local tensors (mps._mps) at idx and idx + 1 will be changed\n",
    "                    mps.center_orthogonalization_(idx + 1, mode=\"qr\", normalize=True)\n",
    "                    # so we need to update aux variables, only env_vectors_left affected\n",
    "                    new_next_env_vector_left, new_norm_factor = calc_left_to_right_step(\n",
    "                        mps_local_tensors[idx],\n",
    "                        env_vectors_left[idx],\n",
    "                        data_at(idx),\n",
    "                    )\n",
    "                    env_vectors_left[idx + 1] = new_next_env_vector_left\n",
    "                    norm_factors[:, idx] = new_norm_factor\n",
    "                else:\n",
    "                    # same as normalize the center tensor, as the center tensor is already at this place\n",
    "                    # we need normalization here to make mps as a unit norm state so to preserve the probability interpretation\n",
    "                    mps.normalize_()\n",
    "\n",
    "            for idx in range(mps.length - 1, -1, -1):\n",
    "                assert idx == mps.center\n",
    "                grad = calc_gradient(\n",
    "                    env_vectors_left[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                    mps_local_tensors[idx],\n",
    "                    enable_tsgo,\n",
    "                )\n",
    "                mps_local_tensors[idx] -= lr * grad\n",
    "                # prepare for the next iteration\n",
    "                if idx > 0:\n",
    "                    # move the center to the left\n",
    "                    # the local tensors (mps._mps) at idx and idx - 1 will be changed\n",
    "                    mps.center_orthogonalization_(idx - 1, mode=\"qr\", normalize=True)\n",
    "                    # so we need to update aux variables, only env_vectors_right affected\n",
    "                    new_next_env_vector_right, new_norm_factor = calc_right_to_left_step(\n",
    "                        mps_local_tensors[idx],\n",
    "                        env_vectors_right[idx],\n",
    "                        data_at(idx),\n",
    "                    )\n",
    "                    env_vectors_right[idx - 1] = new_next_env_vector_right\n",
    "                    norm_factors[:, idx] = new_norm_factor\n",
    "                else:\n",
    "                    # same as normalize the center tensor, as the center tensor is already at this place\n",
    "                    # we need normalization here to make mps as a unit norm state so to preserve the probability interpretation\n",
    "                    mps.normalize_()\n",
    "\n",
    "            assert mps.center == 0\n",
    "            # update the norm factor at the center\n",
    "            norm_factors[:, mps.center] = einsum(\n",
    "                mps_local_tensors[mps.center],\n",
    "                env_vectors_left[mps.center],\n",
    "                data_at(mps.center),\n",
    "                env_vectors_right[mps.center],\n",
    "                \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "            )\n",
    "            batch_nll_loss = calc_nll(norm_factors)\n",
    "            epoch_nll_losses.append(batch_nll_loss)\n",
    "\n",
    "        epoch_nll_loss = torch.cat(epoch_nll_losses).mean()\n",
    "        nll_losses.append(epoch_nll_loss)\n",
    "        progress_bar.set_description(f\"Iter {i} NLL: {epoch_nll_loss:.4f}\")\n",
    "\n",
    "    # restore the default device\n",
    "    torch.set_default_device(prev_device)\n",
    "    return torch.stack(nll_losses), mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:16.865851Z",
     "start_time": "2025-05-13T16:34:16.138893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensor_network.utils.data import get_fashion_mnist_datasets\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tensor_network.feature_mapping import cossin_feature_map\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cache_path = os.path.join(cwd, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:18.901129Z",
     "start_time": "2025-05-13T16:34:17.724184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set, test_set = get_fashion_mnist_datasets(cache_path)\n",
    "t_loader = DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n",
    "train_data, train_labels = next(iter(t_loader))\n",
    "t_loader = DataLoader(test_set, batch_size=len(test_set), shuffle=False)\n",
    "test_data, test_labels = next(iter(t_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:20.469914Z",
     "start_time": "2025-05-13T16:34:20.467098Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cpu\")\n",
    "batch_size = 6000\n",
    "lr = 1e-1\n",
    "sweep_times = 100\n",
    "\n",
    "feature_dim = 2\n",
    "feature_num = 28 * 28\n",
    "virtual_dim = 64\n",
    "\n",
    "train_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:25.067041Z",
     "start_time": "2025-05-13T16:34:25.042041Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_labels == train_class]\n",
    "train_data = train_data.reshape(train_data.shape[0], -1).to(device)\n",
    "train_data = cossin_feature_map(train_data)\n",
    "test_data = test_data[test_labels == train_class]\n",
    "test_data = test_data.reshape(test_data.shape[0], -1).to(device)\n",
    "test_data = cossin_feature_map(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:27.370454Z",
     "start_time": "2025-05-13T16:34:27.324689Z"
    }
   },
   "outputs": [],
   "source": [
    "mps = MPS(\n",
    "    length=feature_num,\n",
    "    physical_dim=feature_dim,\n",
    "    virtual_dim=virtual_dim,\n",
    "    mps_type=MPSType.Periodic,\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    "    requires_grad=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:35:39.067242Z",
     "start_time": "2025-05-13T16:34:36.201843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, nll = 550.1476440429688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ba81eb6b384bf3b0ade2abfa25d9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5167a36fe6524bad93fbf5c68482ccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05bad74297a496bb1e026e8d828f44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m losses, mps = \u001b[43mtrain_gmps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msweep_times\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_tsgo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 249\u001b[39m, in \u001b[36mtrain_gmps\u001b[39m\u001b[34m(samples, batch_size, mps, sweep_times, lr, device, enable_tsgo)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mps.length - \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m idx == mps.center\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     grad = \u001b[43mcalc_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_vectors_left\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_vectors_right\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmps_local_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_tsgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     mps_local_tensors[idx] -= lr * grad\n\u001b[32m    257\u001b[39m     \u001b[38;5;66;03m# prepare for the next iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:655\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    652\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mcalc_gradient\u001b[39m\u001b[34m(env_left_vector, env_right_vector, current_sample, current_tensor, enable_tsgo)\u001b[39m\n\u001b[32m     46\u001b[39m     nll = -\u001b[32m2\u001b[39m * torch.log(norm_factors.abs() + EPS).sum(dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch)\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m nll\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;129m@torch\u001b[39m.compile\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_gradient\u001b[39m(\n\u001b[32m     52\u001b[39m     env_left_vector: torch.Tensor,\n\u001b[32m     53\u001b[39m     env_right_vector: torch.Tensor,\n\u001b[32m     54\u001b[39m     current_sample: torch.Tensor,\n\u001b[32m     55\u001b[39m     current_tensor: torch.Tensor,\n\u001b[32m     56\u001b[39m     enable_tsgo: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m     57\u001b[39m ) -> torch.Tensor:\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m    Calculate the gradient w.r.t. the current tensor\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m     raw_grad = einsum(\n\u001b[32m     62\u001b[39m         env_left_vector,\n\u001b[32m     63\u001b[39m         current_sample,\n\u001b[32m     64\u001b[39m         env_right_vector,\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch left, batch physical, batch right -> batch left physical right\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1201\u001b[39m, in \u001b[36maot_module_simplified.<locals>.forward\u001b[39m\u001b[34m(*runtime_args)\u001b[39m\n\u001b[32m   1199\u001b[39m full_args.extend(params_flat)\n\u001b[32m   1200\u001b[39m full_args.extend(runtime_args)\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:328\u001b[39m, in \u001b[36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n\u001b[32m    327\u001b[39m         torch._C._set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     all_outs = \u001b[43mcall_func_at_runtime_with_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiled_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteal_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:126\u001b[39m, in \u001b[36mcall_func_at_runtime_with_args\u001b[39m\u001b[34m(f, args, steal_args, disable_amp)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         out = normalize_as_list(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    128\u001b[39m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[32m    129\u001b[39m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[32m    130\u001b[39m         warnings.warn(\n\u001b[32m    131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt take boxed arguments. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:689\u001b[39m, in \u001b[36mEffectTokensWrapper.post_compile.<locals>.inner_fn\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    686\u001b[39m     args = [*([\u001b[38;5;28;01mNone\u001b[39;00m] * num_tokens), *args]\n\u001b[32m    687\u001b[39m     old_args.clear()\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m outs = \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;66;03m# Inductor cache DummyModule can return None\u001b[39;00m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:495\u001b[39m, in \u001b[36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[39m\u001b[34m(runtime_args)\u001b[39m\n\u001b[32m    488\u001b[39m     out = \u001b[38;5;28mself\u001b[39m._functionalized_rng_runtime_epilogue(\n\u001b[32m    489\u001b[39m         runtime_metadata,\n\u001b[32m    490\u001b[39m         out,\n\u001b[32m    491\u001b[39m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[32m    492\u001b[39m         runtime_metadata.num_forward_returns,\n\u001b[32m    493\u001b[39m     )\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/offline_code/personal/tensor_network/.venv/lib/python3.12/site-packages/torch/_inductor/output_code.py:460\u001b[39m, in \u001b[36mCompiledFxGraph.__call__\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_callable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    462\u001b[39m     get_runtime_metrics_context().finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/cg/6l5b95y14c18297sgdjvpcbc0000gn/T/torchinductor_zhiqiu/rz/crzdku6qcjdxb34cuhxqdmhejxyck2iu7gm4cyoyicglevesvxyd.py:246\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    244\u001b[39m buf3 = empty_strided_cpu((), (), torch.float32)\n\u001b[32m    245\u001b[39m buf4 = buf1; \u001b[38;5;28;01mdel\u001b[39;00m buf1  \u001b[38;5;66;03m# reuse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m \u001b[43mcpp_fused_bmm_div_dot_linalg_vector_norm_mean_mul_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg3_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg0_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg1_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg2_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m arg0_1\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m arg1_1\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "losses, mps = train_gmps(\n",
    "    samples=train_data,\n",
    "    batch_size=batch_size,\n",
    "    mps=mps,\n",
    "    sweep_times=sweep_times,\n",
    "    lr=lr,\n",
    "    device=device,\n",
    "    enable_tsgo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
