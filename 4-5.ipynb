{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5: 生成式张量网络机器学习及优化算法\n",
    "\n",
    "**ResMPS** : 将张量网络 (MPS) 看作从多个向量到单个向量 (或张量) 的映射，实现分类等预测；\n",
    "\n",
    "**生成式MPS** (generative MPS, 简称GMPS) : 由MPS给出样本的概率分布，实现生成任务。\n",
    "\n",
    "> 核心是波恩概率诠释，见 [2.1](2-1.ipynb)\n",
    "\n",
    "GMPS：将样本出现的概率定义为对该样本进行特征映射后所得量子态与MPS态$|\\phi\\rangle$内积的模方\n",
    "\n",
    "将\"0\"（例如一个白色像素）映射为$|0\\rangle$，将\"1\"（例如一个黑色像素）映射为$|1\\rangle$，则样本\"10101\"被映射为直积态$|10101\\rangle$。对于给定量子态$|\\phi\\rangle$，我们设其为矩阵乘积态，则样本\"10101\"在$|\\phi\\rangle$中出现的概率满足\n",
    "\n",
    "$$p(\\text{\"10101\"}) = \\frac{|\\langle10101|\\phi\\rangle|^2}{\\langle\\phi|\\phi\\rangle}$$\n",
    "\n",
    "![gmps_example](./images/gmps_example.png)\n",
    "\n",
    "> 量子概率性机器学习模型又被称为波恩机\n",
    "\n",
    "## GMPS 训练\n",
    "\n",
    "核心任务：为在保持其量子概率诠释的前提下优化局域张量，使得NLL函数极小\n",
    "\n",
    "损失函数：负对数似然（negative logarithmic likelihood，简称NLL）；\n",
    "\n",
    "在目标概率分布为等概率分布时，NLL与交叉熵（见第三章第3节）仅相差一个常数。\n",
    "\n",
    "具体而言：计算矩阵乘积态对于某个数据集中所有样本的概率分布，并训练矩阵乘积态（即优化局域张量），使得各个样本在矩阵乘积态中出现的概率接近其在数据集中出现的概率。一般而言，各个样本在数据集出现的次数为1，因此，我们需要优化局域张量，使得矩阵乘积态给出的各个样本的概率相等。\n",
    "\n",
    "> NLL函数定义：\n",
    "> \n",
    "> $$f = -\\frac{1}{M}\\sum_{m=0}^{M-1}\\ln\\frac{|\\langle\\phi^{(m)}|\\phi\\rangle|^2}{(\\phi|\\phi)} = -\\frac{1}{M}\\sum_{m=0}^{M-1}[\\ln|\\langle\\phi^{(m)}|\\phi\\rangle|^2-\\ln(\\phi|\\phi)]$$\n",
    "\n",
    "Reference:\n",
    "* [Supervised Learning with Tensor Networks](https://papers.nips.cc/paper_files/paper/2016/hash/5314b9674c86e3f9d1ba25ef9bb32895-Abstract.html)\n",
    "\n",
    "### 张量网络的梯度计算\n",
    "TODO: Add Figure\n",
    "\n",
    "例子：\n",
    "![tensor_network_gradient_calculation_example](./images/tensor_network_gradient_calculation_example.png)\n",
    "\n",
    "> * 梯度的第一项对应于 NLL 的第二项，梯度的第二项对应于 NLL 的第一项，因为合并了最前面的负号\n",
    "> * 梯度第一项的形式需要中心正交形式，例子里的 MPS 的中心必须是在第 2 号局域张量\n",
    "\n",
    "计算的时候可以从两端向正交中心迭代计算，好处是梯度计算公式的上下部分可以复用部分计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:33:50.809089Z",
     "start_time": "2025-05-13T16:33:50.133633Z"
    }
   },
   "outputs": [],
   "source": [
    "# |default_exp algorithms.gmps\n",
    "# |export\n",
    "import torch\n",
    "from tensor_network.mps.modules import MPS, MPSType\n",
    "from einops import einsum\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, List\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:33:52.865784Z",
     "start_time": "2025-05-13T16:33:52.855189Z"
    }
   },
   "outputs": [],
   "source": [
    "# |export\n",
    "EPS = 1e-14\n",
    "\n",
    "\n",
    "# prepare env vectors from left to right\n",
    "def calc_left_to_right_step(\n",
    "    current_tensor: torch.Tensor,\n",
    "    current_env_vector_left: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate one step from left to right of the sweep algorithm\n",
    "    \"\"\"\n",
    "    next_env_vector_left = einsum(\n",
    "        current_env_vector_left,\n",
    "        current_sample,\n",
    "        current_tensor,\n",
    "        \"batch left, batch physical, left physical right -> batch right\",\n",
    "    )\n",
    "    current_norm_factor = next_env_vector_left.norm(dim=1, keepdim=True)\n",
    "    return next_env_vector_left / (current_norm_factor + EPS), current_norm_factor.squeeze(-1)\n",
    "\n",
    "\n",
    "def calc_right_to_left_step(\n",
    "    current_tensor: torch.Tensor,\n",
    "    current_env_vector_right: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate one step from right to left of the sweep algorithm\n",
    "    \"\"\"\n",
    "    next_env_vector_right = einsum(\n",
    "        current_env_vector_right,\n",
    "        current_sample,\n",
    "        current_tensor,\n",
    "        \"batch right, batch physical, left physical right -> batch left\",\n",
    "    )\n",
    "    current_norm_factor = next_env_vector_right.norm(dim=1, keepdim=True)\n",
    "    return next_env_vector_right / (current_norm_factor + EPS), current_norm_factor.squeeze(-1)\n",
    "\n",
    "\n",
    "def calc_nll(norm_factors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the negative log likelihood from the norm factors in a batch\n",
    "    \"\"\"\n",
    "    nll = -2 * torch.log(norm_factors.abs() + EPS).sum(dim=1)  # (batch)\n",
    "    return nll\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def calc_gradient(\n",
    "    env_left_vector: torch.Tensor,\n",
    "    env_right_vector: torch.Tensor,\n",
    "    current_sample: torch.Tensor,\n",
    "    current_tensor: torch.Tensor,\n",
    "    enable_tsgo: bool,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the gradient w.r.t. the current tensor\n",
    "    \"\"\"\n",
    "    raw_grad = einsum(\n",
    "        env_left_vector,\n",
    "        current_sample,\n",
    "        env_right_vector,\n",
    "        \"batch left, batch physical, batch right -> batch left physical right\",\n",
    "    )\n",
    "    # norm = einsum(\n",
    "    #     current_tensor,\n",
    "    #     raw_grad,\n",
    "    #     \"left physical right, batch left physical right -> batch\",\n",
    "    # )\n",
    "    norm = torch.einsum(\"apb,napb->n\", current_tensor, raw_grad)\n",
    "    norm += torch.sign(norm) * EPS  # add a small number to avoid division by zero\n",
    "    # grad = (raw_grad / norm.view(-1, 1, 1, 1)).mean(dim=0)\n",
    "    grad_part = torch.einsum(\"napb,n->apb\", raw_grad, 1 / norm) / norm.numel()\n",
    "    grad = 2 * (current_tensor - grad_part)\n",
    "    grad_shape = grad.shape\n",
    "    assert grad_shape == current_tensor.shape\n",
    "    if enable_tsgo:\n",
    "        grad = grad.reshape(-1)\n",
    "        current_tensor = current_tensor.reshape(-1)\n",
    "        projection = torch.dot(grad, current_tensor) * current_tensor\n",
    "        grad = grad - projection\n",
    "        grad = grad.reshape(grad_shape)\n",
    "\n",
    "    grad /= grad.norm()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def eval_nll(\n",
    "    *,\n",
    "    samples: torch.Tensor,\n",
    "    mps: MPS,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    assert samples.ndim == 3  # (dataset_size, feature_num, feature_dim)\n",
    "    assert mps.center is not None\n",
    "    dataset_size, feature_num, _ = samples.shape\n",
    "    assert feature_num == mps.length\n",
    "    # set default device to device\n",
    "    prev_device = torch.get_default_device()\n",
    "    torch.set_default_device(device)\n",
    "    mps_local_tensors = mps.local_tensors\n",
    "    batch_size = dataset_size  # since we do the init NLL evaluation in one go\n",
    "    env_vectors_left: List[torch.Tensor | None] = [None] * mps.length\n",
    "    left_virtual_dim = mps_local_tensors[0].shape[0]\n",
    "    env_vectors_left[0] = torch.ones(batch_size, left_virtual_dim)\n",
    "    env_vectors_right: List[torch.Tensor | None] = [None] * mps.length\n",
    "    right_virtual_dim = mps_local_tensors[-1].shape[-1]\n",
    "    env_vectors_right[-1] = torch.ones(batch_size, right_virtual_dim)\n",
    "    norm_factors = torch.ones(batch_size, feature_num)\n",
    "\n",
    "    def samples_at(idx):\n",
    "        return samples[:, idx, :]  # (batch, feature_dim)\n",
    "\n",
    "    for idx in range(mps.center):\n",
    "        next_env_vector_left, current_norm_factor = calc_left_to_right_step(\n",
    "            mps_local_tensors[idx],\n",
    "            env_vectors_left[idx],\n",
    "            samples_at(idx),\n",
    "        )\n",
    "        # set the norm factor for current position to be the norm of the next env vector, since the next env vector is to be normalized\n",
    "        norm_factors[:, idx] = current_norm_factor\n",
    "        env_vectors_left[idx + 1] = next_env_vector_left\n",
    "\n",
    "    # prepare env vectors from right to left\n",
    "    for idx in range(mps.length - 1, mps.center, -1):\n",
    "        next_env_vector_right, current_norm_factor = calc_right_to_left_step(\n",
    "            mps_local_tensors[idx],\n",
    "            env_vectors_right[idx],\n",
    "            samples_at(idx),\n",
    "        )\n",
    "        norm_factors[:, idx] = current_norm_factor\n",
    "        env_vectors_right[idx - 1] = next_env_vector_right\n",
    "\n",
    "    # update the norm factor at the center\n",
    "    norm_factors[:, mps.center] = einsum(\n",
    "        mps_local_tensors[mps.center],\n",
    "        env_vectors_left[mps.center],\n",
    "        samples_at(mps.center),\n",
    "        env_vectors_right[mps.center],\n",
    "        \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "    )\n",
    "\n",
    "    nll = calc_nll(norm_factors).mean()\n",
    "    # restore the default device\n",
    "    torch.set_default_device(prev_device)\n",
    "    return nll\n",
    "\n",
    "\n",
    "def train_gmps(\n",
    "    *,\n",
    "    samples: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    mps: MPS,\n",
    "    sweep_times: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    enable_tsgo: bool,\n",
    ") -> Tuple[torch.Tensor, MPS]:\n",
    "    dataset_size = samples.shape[0]\n",
    "    assert dataset_size % batch_size == 0\n",
    "    assert mps.mps_type == MPSType.Open\n",
    "    # prepare mps, normalize first to avoid numerical instability\n",
    "    # mps.normalize_()\n",
    "    mps.center_orthogonalization_(0, mode=\"qr\", normalize=True, check_nan=True)\n",
    "    init_nll = eval_nll(samples=samples, mps=mps, device=device)\n",
    "    print(f\"Initially, nll = {init_nll}\")\n",
    "\n",
    "    # set default device to device\n",
    "    prev_device = torch.get_default_device()\n",
    "    torch.set_default_device(device)\n",
    "    # prepare dataloader\n",
    "    dataloader = DataLoader(TensorDataset(samples), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mps_local_tensors = mps._mps  # CAREFUL for inplace operation\n",
    "    feature_num = mps.length\n",
    "    left_virtual_dim = mps_local_tensors[0].shape[0]\n",
    "    right_virtual_dim = mps_local_tensors[-1].shape[-1]\n",
    "\n",
    "    nll_losses = [init_nll]\n",
    "\n",
    "    progress_bar = tqdm(range(sweep_times))\n",
    "    for i in progress_bar:\n",
    "        epoch_nll_losses = []\n",
    "        for batch_data in tqdm(dataloader, leave=False):\n",
    "            batch_data = batch_data[0]\n",
    "            batch_size = batch_data.shape[0]\n",
    "            # prepare aux variables\n",
    "            env_vectors_left: List[torch.Tensor | None] = [None] * mps.length\n",
    "            env_vectors_left[0] = torch.ones(batch_size, left_virtual_dim)\n",
    "            env_vectors_right: List[torch.Tensor | None] = [None] * mps.length\n",
    "            env_vectors_right[-1] = torch.ones(batch_size, right_virtual_dim)\n",
    "            norm_factors = torch.ones(batch_size, feature_num)\n",
    "\n",
    "            def data_at(idx):\n",
    "                return batch_data[:, idx, :]  # (batch, feature_dim)\n",
    "\n",
    "            # prepare env vectors from right to left\n",
    "            # leave out left-to-right because the center of mps always starts at 0\n",
    "            for idx in range(mps.length - 1, mps.center, -1):\n",
    "                next_env_vector_right, current_norm_factor = calc_right_to_left_step(\n",
    "                    mps_local_tensors[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                )\n",
    "                norm_factors[:, idx] = current_norm_factor\n",
    "                env_vectors_right[idx - 1] = next_env_vector_right\n",
    "\n",
    "            # update the norm factor at the center\n",
    "            norm_factors[:, mps.center] = einsum(\n",
    "                mps_local_tensors[mps.center],\n",
    "                env_vectors_left[mps.center],\n",
    "                data_at(mps.center),\n",
    "                env_vectors_right[mps.center],\n",
    "                \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "            )\n",
    "\n",
    "            # gradient calculation and optimization, from left to right\n",
    "            for idx in range(mps.length):\n",
    "                assert idx == mps.center\n",
    "                grad = calc_gradient(\n",
    "                    env_vectors_left[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                    mps_local_tensors[idx],\n",
    "                    enable_tsgo,\n",
    "                )\n",
    "                # update the tensor with gradient, inplace operation, will change mps._mps\n",
    "                mps_local_tensors[idx] -= lr * grad\n",
    "\n",
    "                # prepare for the next iteration\n",
    "                if idx < mps.length - 1:\n",
    "                    # move the center to the right\n",
    "                    # the local tensors (mps._mps) at idx and idx + 1 will be changed\n",
    "                    mps.center_orthogonalization_(idx + 1, mode=\"qr\", normalize=True)\n",
    "                    # so we need to update aux variables, only env_vectors_left affected\n",
    "                    new_next_env_vector_left, new_norm_factor = calc_left_to_right_step(\n",
    "                        mps_local_tensors[idx],\n",
    "                        env_vectors_left[idx],\n",
    "                        data_at(idx),\n",
    "                    )\n",
    "                    env_vectors_left[idx + 1] = new_next_env_vector_left\n",
    "                    norm_factors[:, idx] = new_norm_factor\n",
    "                else:\n",
    "                    # we need normalization here to make mps as a unit norm state so to preserve the probability interpretation\n",
    "                    mps.center_normalize_()\n",
    "\n",
    "            for idx in range(mps.length - 1, -1, -1):\n",
    "                assert idx == mps.center\n",
    "                grad = calc_gradient(\n",
    "                    env_vectors_left[idx],\n",
    "                    env_vectors_right[idx],\n",
    "                    data_at(idx),\n",
    "                    mps_local_tensors[idx],\n",
    "                    enable_tsgo,\n",
    "                )\n",
    "                mps_local_tensors[idx] -= lr * grad\n",
    "                # prepare for the next iteration\n",
    "                if idx > 0:\n",
    "                    # move the center to the left\n",
    "                    # the local tensors (mps._mps) at idx and idx - 1 will be changed\n",
    "                    mps.center_orthogonalization_(idx - 1, mode=\"qr\", normalize=True)\n",
    "                    # so we need to update aux variables, only env_vectors_right affected\n",
    "                    new_next_env_vector_right, new_norm_factor = calc_right_to_left_step(\n",
    "                        mps_local_tensors[idx],\n",
    "                        env_vectors_right[idx],\n",
    "                        data_at(idx),\n",
    "                    )\n",
    "                    env_vectors_right[idx - 1] = new_next_env_vector_right\n",
    "                    norm_factors[:, idx] = new_norm_factor\n",
    "                else:\n",
    "                    # we need normalization here to make mps as a unit norm state so to preserve the probability interpretation\n",
    "                    mps.center_normalize_()\n",
    "\n",
    "            assert mps.center == 0\n",
    "            # update the norm factor at the center\n",
    "            norm_factors[:, mps.center] = einsum(\n",
    "                mps_local_tensors[mps.center],\n",
    "                env_vectors_left[mps.center],\n",
    "                data_at(mps.center),\n",
    "                env_vectors_right[mps.center],\n",
    "                \"left physical right, batch left, batch physical, batch right -> batch\",\n",
    "            )\n",
    "            batch_nll_loss = calc_nll(norm_factors)\n",
    "            epoch_nll_losses.append(batch_nll_loss)\n",
    "\n",
    "        epoch_nll_loss = torch.cat(epoch_nll_losses).mean()\n",
    "        nll_losses.append(epoch_nll_loss)\n",
    "        progress_bar.set_description(f\"Iter {i} NLL: {epoch_nll_loss:.4f}\")\n",
    "\n",
    "    # restore the default device\n",
    "    torch.set_default_device(prev_device)\n",
    "    return torch.stack(nll_losses), mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:16.865851Z",
     "start_time": "2025-05-13T16:34:16.138893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensor_network.utils.data import get_fashion_mnist_datasets\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tensor_network.feature_mapping import cossin_feature_map\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cache_path = os.path.join(cwd, \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:18.901129Z",
     "start_time": "2025-05-13T16:34:17.724184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set, test_set = get_fashion_mnist_datasets(cache_path)\n",
    "t_loader = DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n",
    "train_data, train_labels = next(iter(t_loader))\n",
    "t_loader = DataLoader(test_set, batch_size=len(test_set), shuffle=False)\n",
    "test_data, test_labels = next(iter(t_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:20.469914Z",
     "start_time": "2025-05-13T16:34:20.467098Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cpu\")\n",
    "batch_size = len(train_set)  # mega batch, can change to micro batch\n",
    "lr = 1e-1\n",
    "sweep_times = 10\n",
    "\n",
    "feature_dim = 2\n",
    "feature_num = 28 * 28\n",
    "virtual_dim = 64\n",
    "\n",
    "train_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:25.067041Z",
     "start_time": "2025-05-13T16:34:25.042041Z"
    }
   },
   "outputs": [],
   "source": [
    "theta = 0.5  # theta is important to map the feature in range [0, 1]\n",
    "\n",
    "train_data = train_data[train_labels == train_class]\n",
    "train_data = train_data.reshape(train_data.shape[0], -1).to(device)\n",
    "train_data = cossin_feature_map(train_data, theta=theta)\n",
    "test_data = test_data[test_labels == train_class]\n",
    "test_data = test_data.reshape(test_data.shape[0], -1).to(device)\n",
    "test_data = cossin_feature_map(test_data, theta=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:34:27.370454Z",
     "start_time": "2025-05-13T16:34:27.324689Z"
    }
   },
   "outputs": [],
   "source": [
    "mps = MPS(\n",
    "    length=feature_num,\n",
    "    physical_dim=feature_dim,\n",
    "    virtual_dim=virtual_dim,\n",
    "    mps_type=MPSType.Open,\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    "    requires_grad=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T16:35:39.067242Z",
     "start_time": "2025-05-13T16:34:36.201843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, nll = 557.891845703125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ebcebcee142c6a6bdbf774b295ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae0cdf972f24e169f978680842640e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d44d5794207449699f3d5da62ff63c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dd92213077498d9eef1b3e3bcd8019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d494817a71544590970c1b792d60c215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c86266538a449ba74da0a3b1c14b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beb6c6b3e164d80a1111acd07c19e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2117f26d850544c68518f3abb48be373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2cff725b2941cebc2f230597b76416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc594695b62d4d61bc1a0a37fc86c721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79850d85a07c4d15891d774d74346448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FIXME: gradient calculation problem? convergence is too slow\n",
    "losses, mps = train_gmps(\n",
    "    samples=train_data,\n",
    "    batch_size=batch_size,\n",
    "    mps=mps,\n",
    "    sweep_times=sweep_times,\n",
    "    lr=lr,\n",
    "    device=device,\n",
    "    enable_tsgo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
