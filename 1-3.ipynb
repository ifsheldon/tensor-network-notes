{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.329004Z",
     "start_time": "2025-03-17T09:12:43.631888Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0dd7570845d2b6",
   "metadata": {},
   "source": [
    "## 指标收缩\n",
    "\n",
    "### 指标收缩的重要函数：einsum\n",
    "\n",
    "\n",
    "*   其输入为字符串公式与相关张量；\n",
    "*   公式包含箭头 \"->\"，箭头左侧为各个待收缩张量的指标，右侧为收缩所得张量的指标；\n",
    "*   左侧各个张量的指标用逗号隔开，共有指标使用同一个字母表示；\n",
    "*   当左侧出现的指标没有出现在右侧时，说明对该指标作求和运算；\n",
    "*   例：$T_k = \\sum_{ij} A_{ijk} B_{ik} C_{jk}$ 的代码为 `T = torch.einsum('ijk,ik,jk->k', A, B, C)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6e28db980d8e9",
   "metadata": {},
   "source": "#### 例子：向量内积"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ace500d7672580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.333519Z",
     "start_time": "2025-03-17T09:12:44.331818Z"
    }
   },
   "outputs": [],
   "source": [
    "u = torch.randn(4)\n",
    "v = torch.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd1ed098a3e0c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.463153Z",
     "start_time": "2025-03-17T09:12:44.459229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1=tensor(2.5590), t1=tensor(1.0885)\n",
      "t2=tensor(1.0885)\n"
     ]
    }
   ],
   "source": [
    "z1 = u.dot(v)\n",
    "z2 = u.inner(v)\n",
    "z3 = torch.einsum(\"i,i->\", u, v)\n",
    "z4 = (u * v).sum()\n",
    "\n",
    "# Try\n",
    "t1 = torch.einsum(\"a,b->\", u, v)\n",
    "\n",
    "assert z1.isclose(z2) and z1.isclose(z3) and z1.isclose(z4)\n",
    "assert not z1.isclose(t1)\n",
    "\n",
    "print(f\"{z1=}, {t1=}\")\n",
    "\n",
    "t2 = (u.reshape(4, 1) * v.reshape(1, 4)).sum()\n",
    "assert t1.isclose(t2)\n",
    "print(f\"{t2=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c53fee1f82a0c4",
   "metadata": {},
   "source": [
    "b$z_1 = z_2 = z_3 = z_4 = \\sum_{i} u_i \\cdot v_i$\n",
    "\n",
    "but $t_1 = t_2 = \\sum_{a} \\sum_{b} u_a \\cdot v_b$ which is equivalent to a kronecker product and then a sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da251e0265fba201",
   "metadata": {},
   "source": [
    "#### 例子：矩阵乘积\n",
    "矩阵乘：$X = PQ \\leftrightarrow X_{ik} = \\sum_j P_{ij} Q_{jk}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c4478913f5bfa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.468905Z",
     "start_time": "2025-03-17T09:12:44.467370Z"
    }
   },
   "outputs": [],
   "source": [
    "P = torch.randn(3, 4)\n",
    "Q = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad379b339c831f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.481587Z",
     "start_time": "2025-03-17T09:12:44.479594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4166,  3.4424, -4.2510, -0.2182, -0.4939],\n",
      "        [ 0.1289, -0.9257,  1.3034,  0.1052,  0.4339],\n",
      "        [ 0.6358, -1.4259,  0.8684,  1.1713, -2.3189]])\n"
     ]
    }
   ],
   "source": [
    "X1 = P @ Q\n",
    "X2 = torch.matmul(P, Q)\n",
    "X3 = torch.einsum(\"ij,jk->ik\", P, Q)\n",
    "\n",
    "assert X1.allclose(X2) and X1.allclose(X3)\n",
    "\n",
    "print(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b503a79350f7",
   "metadata": {},
   "source": "#### 例子：张量收缩"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747e555721f12a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.504669Z",
     "start_time": "2025-03-17T09:12:44.502629Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "j = 3\n",
    "k = 4\n",
    "a = 5\n",
    "b = 6\n",
    "c = 7\n",
    "\n",
    "A = torch.randn(i, a, j)\n",
    "B = torch.randn(j, b, k)\n",
    "C = torch.randn(k, c, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19813bbc8978943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.512161Z",
     "start_time": "2025-03-17T09:12:44.510539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.einsum(\"iaj, jbk, kci->abc\", A, B, C)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e2306a08114d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T09:12:44.526140Z",
     "start_time": "2025-03-17T09:12:44.523913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "## To contract index j\n",
    "tmp_a = A.reshape(i * a, j)\n",
    "tmp_b = B.reshape(j, b * k)\n",
    "tmp_iabk = (tmp_a @ tmp_b).reshape(i, a, b, k)\n",
    "\n",
    "## To contract index i and k\n",
    "tmp_abki = tmp_iabk.permute(1, 2, 3, 0)\n",
    "tmp_ab_ki = tmp_abki.reshape(a * b, k * i)\n",
    "tmp_c_kic = C.permute(0, 2, 1)\n",
    "tmp_c_ki_c = tmp_c_kic.reshape(k * i, c)\n",
    "X1 = (tmp_ab_ki @ tmp_c_ki_c).reshape(a, b, c)\n",
    "\n",
    "assert X.allclose(X1)\n",
    "\n",
    "# Try\n",
    "tmp_c_ikc = C.permute(2, 0, 1)\n",
    "tmp_c_ik_c = tmp_c_ikc.reshape(i * k, c)\n",
    "Try_X = (tmp_ab_ki @ tmp_c_ik_c).reshape(a, b, c)\n",
    "assert not X.allclose(Try_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
