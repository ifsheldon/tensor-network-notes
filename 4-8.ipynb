{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.8: 量子核与懒惰态\n",
    "\n",
    "> References:\n",
    "> _Generative tensor network classification model for supervised machine learning_\n",
    "> _Non-Parametric Semi-Supervised Learning in Many-Body Hilbert Space with Rescaled Logarithmic Fidelity_\n",
    "\n",
    "## 懒惰态\n",
    "\n",
    "GMPSC (或更一般的GTNC) 可简单地构造出NLL的极小点：\n",
    "\n",
    "$$|\\psi\\rangle = \\frac{1}{\\sqrt{N}} \\sum_{n=0}^{N-1} e^{i\\theta_n}|\\Phi^{(n)}\\rangle$$\n",
    "\n",
    "$|\\Phi^{(n)}\\rangle = \\prod_{l=0}^{L-1}|\\phi^{(n,l)}\\rangle$，其中$|\\phi^{(n,l)}\\rangle$ 为第 $n$ 个样本的第 $l$ 个特征经过特征映射后得到的单比特量子态，$L$ 为每个样本的总特征数，$N$ 为总样本数；$\\theta_n$ 代表第 $n$ 个样本对应的相位因子，由于 $|e^{i\\theta_n}| = 1$，$\\theta_n$ 的取值不影响样本出现的概率。\n",
    "\n",
    "上述量子态满足使NLL极小的等概率分布，即\n",
    "\n",
    "$$|\\langle\\Phi^{(0)}|\\psi\\rangle|^2 \\approx |\\langle\\Phi^{(1)}|\\psi\\rangle|^2 \\approx ... \\approx |\\langle\\Phi^{(N-1)}|\\psi\\rangle|^2 \\approx \\frac{1}{N}$$\n",
    "\n",
    "(参考4.4节)\n",
    "\n",
    "我们将该态成为懒惰量子态 (lazy quantum state)，或简称懒惰态。\n",
    "\n",
    "### 前提条件\n",
    "\n",
    "等概率分布近似成立的前提：正交灾难，即两个样本量子态间的保真度满足\n",
    "\n",
    "$$f(\\boldsymbol{x}^{(n)}, \\boldsymbol{x}^{(n')}) = |\\langle\\Phi^{(n')}|\\Phi^{(n)}\\rangle| \\approx \\delta_{n'n}$$\n",
    "\n",
    "> $\\delta$ 是一个矩阵，对角线元素为 1，非对角线元素近似为 0\n",
    "\n",
    "此时，某个样本出现的概率满足\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{x}^{(n')}) \n",
    "&= |\\langle\\Phi^{(n')}|\\psi\\rangle|^2 \\\\\n",
    "&= \\frac{1}{N}\\left|\\sum_{n=0}^{N-1}\\langle\\Phi^{(n')}|e^{i\\theta_n}\\Phi^{(n)}\\rangle\\right|^2 \\\\\n",
    "&\\lesssim \\frac{1}{N}\\sum_{n=0}^{N-1}\\left|\\langle\\Phi^{(n')}|e^{i\\theta_n}\\Phi^{(n)}\\rangle\\right|^2 \\\\\n",
    "&\\approx \\frac{1}{N}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "例：cos-sin特征映射中 $x_l^{(n)} \\rightarrow \\cos\\frac{\\pi}{2}x_l^{(n)}|0\\rangle + \\sin\\frac{\\pi}{2}x_l^{(n)}|1\\rangle$（见第三章相关内容），有\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\boldsymbol{x}^{(n)}, \\boldsymbol{x}^{(n')})\n",
    "&= \\prod_{l=0}^{L-1} (\\cos\\frac{\\pi}{2}x_l^{(n)} \\cos\\frac{\\pi}{2}x_l^{(n')} +  \\sin\\frac{\\pi}{2}x_l^{(n)} \\sin\\frac{\\pi}{2}x_l^{(n')}) \\\\\n",
    "&= \\prod_{l=0}^{L-1}\\cos\\frac{\\pi}{2}(x_l^{(n)} - x_l^{(n')})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "保真度是由 $L$ 个小于等于1的数连乘获得，因此其值指数接近于零。\n",
    "\n",
    "## 核函数 Kernel Function\n",
    "\n",
    "保真度 $f(x^{(n)},x^{(n')}) = \\prod_{l=0}^{L-1} \\cos\\frac{\\pi}{2}(x_l^{(n)} - x_l^{(n')})$ 正是**余弦相似性**(cosine similarity)，为\"经典\"机器学习中常用的核函数(kernel function)。可见，特征映射与量子态保真度联合定义的样本相似性度量，可以是一个\"经典\"的相似性度量。\n",
    "\n",
    "(注：核函数定义为从两个样本到距离度量值的半正定函数)\n",
    "\n",
    "克服正交灾难的方法之一：发展新的核函数，例如负对数保真度\n",
    "\n",
    "$$F(x^{(n)},x^{(n')}) = -\\frac{1}{L}\\ln f(x^{(n)},x^{(n')}) = -\\frac{1}{L}\\sum_{l=0}^{L-1}\\ln\\cos\\frac{\\pi(x_l^{(n)}-x_l^{(n')})}{2}$$\n",
    "\n",
    "显然 $F$ 仅随 $L$ 线性变化，从而避免了正交灾难。\n",
    "\n",
    "另一个例子：重标度对数保真度\n",
    "\n",
    "$$f(x^{(n)},x^{(n')};\\beta) = \\beta^{F(x^{(n)},x^{(n')})}$$\n",
    "\n",
    "重标度因子 $\\beta$ 控制\"发散\"速度，一般取 $\\beta > 1$。当 $\\beta=e$ 时，重标度对数保真度还原为原来的保真度。\n",
    "\n",
    "小结：\n",
    "* 核函数为从两个样本到二者间测度的映射，量子核函数由**量子特征映射**与（希尔伯特空间中）量子态间的**距离测度函数**共同定义\n",
    "* 可通过定义量子核函数，避免希尔伯特空间中的正交灾难，并调节样本间的相对距离\n",
    "* 用不同的核函数定义可避免正交灾难，但并不影响量子态间的正交性（这里的正交性总是由内积或保真度定义），因此并不影响懒惰态的等概率分布推导\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
