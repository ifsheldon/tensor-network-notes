{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2: 矩阵乘积态的中心正交形式（Central Orthogonal Form）\n",
    "\n",
    "## 理论基础\n",
    "\n",
    "中心正交化的理论基础是矩阵乘积态的规范自由度 (gauge degrees of freedom)\n",
    "\n",
    "简而言之：不同的局域张量构成的矩阵乘积态可以对应相同的全局张量\n",
    "\n",
    "![gauge_transformation_example](./images/gauge_transformation_example.png)\n",
    "\n",
    "> 在虚拟指标中间插入一个 Unitary 和它的 Hermitian 不会改变全局张量\n",
    "\n",
    "中心正交形式的矩阵乘积态是通过引入对各个局域张量的正交、归一约束条件，消除（绝大部分）的规范自由度\n",
    "\n",
    "## 中心正交形式的约束条件\n",
    "\n",
    "* 正交中心左侧的张量满足从左至右的正交条件：$(A_{[0,1]}^{(n)})^\\dagger A_{[0,1]}^{(n)} = I \\quad (n < n_c)$\n",
    "* 正交中心右侧的张量满足从右至左的正交条件：$A_{[0]}^{(n)}(A_{[0]}^{(n)})^\\dagger = I \\quad (n > n_c)$\n",
    "* 对于归一化矩阵乘积态，正交中心处的张量（被称为中心张量）满足归一化条件：$|A^{(n_c)}| = 1$\n",
    "\n",
    "![central-orthogonal-form](./images/central_orthogonal_form_illustration.png)\n",
    "* 正交方向由虚拟指标上的箭头标记\n",
    "* (b)和(c)又称等距(isometric)条件，意味着对应的张量为等距张量\n",
    "\n",
    "## 中心正交化\n",
    "\n",
    "将给定矩阵乘积态转换为中心正交形式：从左至右地分解正交中心左侧的张量，以及从右至左地分解正交中心右侧的张量，使得正交中心两侧的所有张量满足相应的正交条件\n",
    "\n",
    "![central-orthogonalization-left-to-right](./images/central-orgonalization-left-to-right.png)\n",
    "\n",
    "从左至右的分解公式：\n",
    "\n",
    "$A_{[0,1]}^{(n)} \\stackrel{\\text{SVD}}{\\longrightarrow} \\tilde{A}^{(n)}SV$\n",
    "\n",
    "$SVA_{[0]}^{(n+1)} \\stackrel{\\text{收缩、变形}}{\\longrightarrow} A^{(n+1)}$\n",
    "\n",
    "\n",
    "性质：\n",
    "* 新获得的$A^{(n)}$与$A^{(n+1)}$的收缩等于变换之前$A^{(n)}$与$A^{(n+1)}$的收缩；\n",
    "* 因此，中心正交化不改变全局张量，因此属于**规范变换**（gauge transformation）；\n",
    "* 也可采用QR分解\n",
    "\n",
    "## 中心正交矩阵乘积态的性质\n",
    "* 全局张量的模等于中心张量的模\n",
    "* 通过中心张量的奇异值分解可获得 MPS 的纠缠\n",
    "    * 目标：考虑在**正交中心**左侧的虚拟指标处，对量子态进行二分并求其二分纠缠谱。\n",
    "    * 一般做法为对全局张量进行矩阵化：将正交中心左侧的所有物理变形为矩阵左指标，其余指标变形为右指标。该矩阵化的奇异谱即为上述二分下的纠缠谱。\n",
    "    * 在中心正交形式下，该奇异谱等于中心张量矩阵化 $A^{(n)}_{[0]}$ 的奇异谱。\n",
    "    * 在**正交中心**右侧的虚拟指标处，对量子态进行二分并求其二分纠缠谱的做法类似\n",
    "    ![center-tensor-singular-spetrum-example](./images/center_tensor_singular_spectrum_example.png)\n",
    "* 约化密度矩阵（reduceddensitymatrix）的计算可以加速\n",
    "    * 定义：$\\hat{\\rho}^{(n)} = Tr_n|\\varphi\\rangle\\langle\\varphi|$\n",
    "    * 部分正交张量的计算可以被省略，从而提升计算效率\n",
    "        * 当不求迹指标位于正交中心时，MPS的约化密度矩阵等于中心张量约化密度矩阵（下图 a）\n",
    "        * 当不求迹指标不位于正交中心时，需处理该指标与正交中心间的张量，来计算MPS的约化密度矩阵 （下图 b）\n",
    "        ![mps_cof_reducted_density_matrix](./images/mps_cof_reduced_density_matrix_illustration.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp mps.modules\n",
    "# |export\n",
    "import torch\n",
    "from typing import List, Tuple, Literal\n",
    "from tensor_network.mps.functional import gen_random_mps_tensors, MPSType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalization One Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export mps.functional\n",
    "from typing import Literal, Tuple\n",
    "\n",
    "\n",
    "def orthogonalize_left2right_step(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    local_tensor_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_locals: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    One step of orthogonalization from left to right, which will make the local tensor isometric and the right one to it transformed.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        local_tensor_idx: int, the index of the local tensor to be orthogonalized.\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_locals: bool, whether to return the local tensors. If True, only the local and the right one will be returned.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after one step of orthogonalization from left to right.\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 0 <= local_tensor_idx < length - 1, \"local_tensor_idx must be in [0, length - 2]\"\n",
    "    mode = mode.lower()\n",
    "    assert mode in [\"svd\", \"qr\"], \"mode must be either 'svd' or 'qr'\"\n",
    "    local_tensor = mps_tensors[local_tensor_idx]\n",
    "    shape = local_tensor.shape  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    if truncate_dim is not None:\n",
    "        virtual_dim = shape[2]\n",
    "        assert truncate_dim > 0, \"truncate_dim must be positive\"\n",
    "        truncate_dim = min(truncate_dim, virtual_dim)\n",
    "        assert mode == \"svd\", \"mode must be 'svd' when truncate_dim is provided\"\n",
    "        need_truncate = True\n",
    "    else:\n",
    "        need_truncate = False\n",
    "\n",
    "    view_matrix = local_tensor.view(-1, shape[2])\n",
    "\n",
    "    if mode == \"svd\":\n",
    "        u, lm, v = torch.linalg.svd(view_matrix, full_matrices=False)\n",
    "        if need_truncate:\n",
    "            u = u[:, :truncate_dim]\n",
    "            lm = lm[:truncate_dim]  # (truncate_dim)\n",
    "            v = v[:truncate_dim, :]  # (truncate_dim, virtual_dim)\n",
    "            r = lm.unsqueeze(1) * v  # (truncate_dim, virtual_dim)\n",
    "        else:\n",
    "            r = lm.unsqueeze(1) * v  # (virtual_dim, virtual_dim)\n",
    "    else:\n",
    "        u, r = torch.linalg.qr(view_matrix)\n",
    "\n",
    "    new_local_tensor = u.reshape(\n",
    "        shape[0], shape[1], -1\n",
    "    )  # (virtual_dim, physical_dim, virtual_dim or truncate_dim)\n",
    "    local_tensor_right = mps_tensors[\n",
    "        local_tensor_idx + 1\n",
    "    ]  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    new_local_tensor_right = torch.einsum(\"ab,bcd->acd\", r, local_tensor_right)\n",
    "    if return_locals:\n",
    "        return new_local_tensor, new_local_tensor_right\n",
    "    else:\n",
    "        return (\n",
    "            mps_tensors[:local_tensor_idx]\n",
    "            + [new_local_tensor, new_local_tensor_right]\n",
    "            + mps_tensors[local_tensor_idx + 2 :]\n",
    "        )\n",
    "\n",
    "\n",
    "def orthogonalize_right2left_step(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    local_tensor_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_locals: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    One step of orthogonalization from right to left, which will make the local tensor isometric and the left one to it transformed.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        local_tensor_idx: int, the index of the local tensor to be orthogonalized.\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_locals: bool, whether to return the local tensors. If True, only the local and the left one will be returned.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after one step of orthogonalization from right to left.\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 1 <= local_tensor_idx < length, \"local_tensor_idx must be in [1, length - 1]\"\n",
    "    mode = mode.lower()\n",
    "    assert mode in [\"svd\", \"qr\"], \"mode must be either 'svd' or 'qr'\"\n",
    "    local_tensor = mps_tensors[local_tensor_idx]\n",
    "    shape = local_tensor.shape  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    if truncate_dim is not None:\n",
    "        virtual_dim = shape[0]\n",
    "        assert truncate_dim > 0, \"truncate_dim must be positive\"\n",
    "        truncate_dim = min(truncate_dim, virtual_dim)\n",
    "        assert mode == \"svd\", \"mode must be 'svd' when truncate_dim is provided\"\n",
    "        need_truncate = True\n",
    "    else:\n",
    "        need_truncate = False\n",
    "\n",
    "    view_matrix = local_tensor.view(\n",
    "        shape[0], -1\n",
    "    ).t()  # (virtual_dim, virtual_dim * physical_dim) -> (virtual_dim * physical_dim, virtual_dim)\n",
    "    if mode == \"svd\":\n",
    "        u, lm, v = torch.linalg.svd(view_matrix, full_matrices=False)\n",
    "        if need_truncate:\n",
    "            u = u[:, :truncate_dim]\n",
    "            lm = lm[:truncate_dim]  # (truncate_dim)\n",
    "            v = v[:truncate_dim, :]  # (truncate_dim, virtual_dim)\n",
    "            r = lm.unsqueeze(1) * v  # (truncate_dim, virtual_dim)\n",
    "        else:\n",
    "            r = lm.unsqueeze(1) * v  # (virtual_dim, virtual_dim)\n",
    "    else:\n",
    "        u, r = torch.linalg.qr(view_matrix)\n",
    "\n",
    "    new_local_tensor = u.t().reshape(\n",
    "        -1, shape[1], shape[2]\n",
    "    )  # (virtual_dim or truncate_dim, physical_dim, virtual_dim)\n",
    "    local_tensor_left = mps_tensors[\n",
    "        local_tensor_idx - 1\n",
    "    ]  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    new_local_tensor_left = torch.einsum(\"abc,dc->abd\", local_tensor_left, r)\n",
    "    if return_locals:\n",
    "        return new_local_tensor_left, new_local_tensor\n",
    "    else:\n",
    "        return (\n",
    "            mps_tensors[: local_tensor_idx - 1]\n",
    "            + [new_local_tensor_left, new_local_tensor]\n",
    "            + mps_tensors[local_tensor_idx + 1 :]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_network import setup_ref_code_import\n",
    "from Library.MatrixProductState import MPS_basic\n",
    "from copy import deepcopy\n",
    "\n",
    "length = 8\n",
    "\n",
    "para = {\"length\": length, \"d\": 3, \"chi\": 4, \"dtype\": torch.complex128}\n",
    "\n",
    "for i in range(length - 1):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_left2right(i, \"svd\")\n",
    "    orthogonalized_mps_tensors = orthogonalize_left2right_step(mps_tensors, i, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(length - 1):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_left2right(i, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors = orthogonalize_left2right_step(\n",
    "        mps_tensors, i, \"svd\", truncate_dim=2\n",
    "    )\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "\n",
    "for i in range(1, length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_right2left(i, \"svd\")\n",
    "    orthogonalized_mps_tensors = orthogonalize_right2left_step(mps_tensors, i, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(1, length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_right2left(i, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors = orthogonalize_right2left_step(\n",
    "        mps_tensors, i, \"svd\", truncate_dim=2\n",
    "    )\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export mps.functional\n",
    "def orthogonalize_arange(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_changed: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[List[torch.Tensor], List[int]]:\n",
    "    \"\"\"\n",
    "    Perform orthogonalization on the range of tensors.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        start_idx: int, the start index of the range\n",
    "        end_idx: int, the end index of the range\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_changed: bool, whether to return the changed tensors. If True, changed tensors' indices will be returned as well.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after orthogonalization\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 0 <= start_idx < length and 0 <= end_idx < length, (\n",
    "        \"start_idx and end_idx must be in [0, length - 1]\"\n",
    "    )\n",
    "    mps_tensors = [m for m in mps_tensors]\n",
    "    changed_indices = set()\n",
    "    if start_idx < end_idx:\n",
    "        for idx in range(start_idx, end_idx, 1):\n",
    "            local, local_right = orthogonalize_left2right_step(\n",
    "                mps_tensors, idx, mode, truncate_dim, return_locals=True\n",
    "            )\n",
    "            mps_tensors[idx] = local\n",
    "            mps_tensors[idx + 1] = local_right\n",
    "            changed_indices.add(idx)\n",
    "            changed_indices.add(idx + 1)\n",
    "    elif start_idx > end_idx:\n",
    "        for idx in range(start_idx, end_idx, -1):\n",
    "            local_left, local = orthogonalize_right2left_step(\n",
    "                mps_tensors, idx, mode, truncate_dim, return_locals=True\n",
    "            )\n",
    "            mps_tensors[idx - 1] = local_left\n",
    "            mps_tensors[idx] = local\n",
    "            changed_indices.add(idx - 1)\n",
    "            changed_indices.add(idx)\n",
    "    else:\n",
    "        # do nothing when start_idx == end_idx\n",
    "        pass\n",
    "\n",
    "    if return_changed:\n",
    "        changed_indices = list(changed_indices)\n",
    "        changed_indices.sort()\n",
    "        return mps_tensors, changed_indices\n",
    "    else:\n",
    "        return mps_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "num_trials = 20\n",
    "\n",
    "length = 8\n",
    "\n",
    "para = {\"length\": length, \"d\": 3, \"chi\": 4, \"dtype\": torch.complex128}\n",
    "\n",
    "i = 0\n",
    "while i < num_trials:\n",
    "    start_idx = randint(0, length - 1)\n",
    "    end_idx = randint(0, length - 1)\n",
    "    if start_idx == end_idx:\n",
    "        continue\n",
    "    i += 1\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_n1_n2(start_idx, end_idx, \"svd\", -1, False)\n",
    "    orthogonalized_mps_tensors = orthogonalize_arange(mps_tensors, start_idx, end_idx, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "\n",
    "# with truncate_dim = 2\n",
    "i = 0\n",
    "while i < num_trials:\n",
    "    start_idx = randint(0, length - 1)\n",
    "    end_idx = randint(0, length - 1)\n",
    "    if start_idx == end_idx:\n",
    "        continue\n",
    "    i += 1\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_n1_n2(start_idx, end_idx, \"svd\", 2, False)\n",
    "    orthogonalized_mps_tensors = orthogonalize_arange(mps_tensors, start_idx, end_idx, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPS Module and Center Orthogonalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from tensor_network.mps.functional import (\n",
    "    orthogonalize_arange,\n",
    "    calc_global_tensor_by_tensordot,\n",
    "    calculate_mps_norm_factors,\n",
    "    calc_inner_product,\n",
    "    tt_decomposition,\n",
    ")\n",
    "import sys\n",
    "from einops import einsum\n",
    "\n",
    "\n",
    "class MPS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        mps_tensors: List[torch.Tensor] | None = None,\n",
    "        length: int | None = None,\n",
    "        physical_dim: int | None = None,\n",
    "        virtual_dim: int | None = None,\n",
    "        mps_type: MPSType | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "        device: torch.device | None = None,\n",
    "        requires_grad: bool | None = None,\n",
    "    ) -> None:\n",
    "        if mps_tensors is None:\n",
    "            assert (\n",
    "                length is not None\n",
    "                and physical_dim is not None\n",
    "                and virtual_dim is not None\n",
    "                and mps_type is not None\n",
    "                and dtype is not None\n",
    "                and device is not None\n",
    "                and requires_grad is not None\n",
    "            ), (\n",
    "                f\"mps_tensors is None, so all arguments must be provided, but got {mps_tensors=}, {length=}, {physical_dim=}, {virtual_dim=}, {mps_type=}, {dtype=}, {device=}, {requires_grad=}\"\n",
    "            )\n",
    "            mps_tensors = gen_random_mps_tensors(\n",
    "                length, physical_dim, virtual_dim, mps_type, dtype, device\n",
    "            )\n",
    "            for i in range(len(mps_tensors)):\n",
    "                mps_tensors[i].requires_grad = requires_grad\n",
    "            self._length: int = length\n",
    "            self._physical_dim: int = physical_dim\n",
    "            self._virtual_dim: int = virtual_dim\n",
    "            self._mps_type: MPSType = mps_type\n",
    "            self._dtype: torch.dtype = dtype\n",
    "            self._device: torch.device = device\n",
    "        else:\n",
    "            # TODO: checking whether the mps_tensors is valid, not emergent\n",
    "            self._length: int = len(mps_tensors)\n",
    "            self._physical_dim: int = mps_tensors[0].shape[1]\n",
    "            self._virtual_dim: int = mps_tensors[0].shape[2]\n",
    "            self._mps_type: MPSType = (\n",
    "                MPSType.Open if mps_tensors[0].shape[0] == 1 else MPSType.Periodic\n",
    "            )\n",
    "            self._dtype: torch.dtype = mps_tensors[0].dtype\n",
    "            self._device: torch.device = mps_tensors[0].device\n",
    "            requires_grad = mps_tensors[0].requires_grad if requires_grad is None else requires_grad\n",
    "\n",
    "        self._requires_grad: bool = requires_grad\n",
    "        self._mps: List[torch.Tensor] = mps_tensors\n",
    "        self._center: int | None = None\n",
    "\n",
    "    def center_orthogonalization_(\n",
    "        self, center: int, mode: Literal[\"svd\", \"qr\"], truncate_dim: int | None = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform center orthogonalization on the MPS. This is an in-place operation.\n",
    "\n",
    "        Args:\n",
    "            center: int, the center of the MPS.\n",
    "            mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "            truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        \"\"\"\n",
    "        assert -self.length <= center < self.length, \"center out of range\"\n",
    "        if center < 0:\n",
    "            center = self.length + center\n",
    "        if self._center is None:\n",
    "            new_local_tensors = orthogonalize_arange(self._mps, 0, center, mode, truncate_dim)\n",
    "            new_local_tensors = orthogonalize_arange(\n",
    "                new_local_tensors, self.length - 1, center, mode, truncate_dim\n",
    "            )\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = new_local_tensors[i]\n",
    "        elif self.center != center:\n",
    "            new_local_tensors, changed_indices = orthogonalize_arange(\n",
    "                self._mps, self.center, center, mode, truncate_dim, return_changed=True\n",
    "            )\n",
    "            for changed_idx in changed_indices:\n",
    "                self._mps[changed_idx] = new_local_tensors[changed_idx]\n",
    "        else:\n",
    "            # when self.center == center\n",
    "            pass\n",
    "        self._center = center\n",
    "\n",
    "    def force_set_local_tensor_(self, i: int, value: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Force set the local tensor at index i to the given value with checking the shape and dtype.\n",
    "\n",
    "        Args:\n",
    "            i: int, the index of the local tensor to be set.\n",
    "            value: torch.Tensor, the value to be set.\n",
    "        \"\"\"\n",
    "        value = value.to(dtype=self._dtype, device=self._device)\n",
    "        value.requires_grad = self._requires_grad\n",
    "        self._mps[i] = value\n",
    "\n",
    "    def __getitem__(self, i: int) -> torch.Tensor:\n",
    "        return self._mps[i]\n",
    "\n",
    "    def __setitem__(self, i: int, value: torch.Tensor):\n",
    "        local_tensor_shape = self[i].shape\n",
    "        local_tensor_dtype = self[i].dtype\n",
    "        assert value.shape == local_tensor_shape, (\n",
    "            f\"value shape must match local tensor shape {local_tensor_shape}, but got {value.shape}\"\n",
    "        )\n",
    "        assert value.dtype == local_tensor_dtype, (\n",
    "            f\"value dtype must match local tensor dtype {local_tensor_dtype}, but got {value.dtype}\"\n",
    "        )\n",
    "        self.force_set_local_tensor_(i, value)\n",
    "\n",
    "    def global_tensor(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the global tensor of the MPS.\n",
    "        \"\"\"\n",
    "        # use tensordot to contract the mps tensors, because it's faster than calc_global_tensor_by_contract\n",
    "        if self.length > 15:\n",
    "            print(\n",
    "                \"Warning: Calculating global tensor of MPS with length > 15, this may up all the memory\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "        return calc_global_tensor_by_tensordot(self._mps)\n",
    "\n",
    "    def norm_factors(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the norm factors of the MPS.\n",
    "        \"\"\"\n",
    "        return calculate_mps_norm_factors(self._mps).real\n",
    "\n",
    "    def norm(self, *, _efficient_mode: bool = True) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the norm of the MPS.\n",
    "        \"\"\"\n",
    "        if _efficient_mode and self.center is not None:\n",
    "            return self._mps[self.center].norm()\n",
    "        else:\n",
    "            norm_factors = self.norm_factors()\n",
    "            # use sqrt inside the product to avoid overflow\n",
    "            return torch.prod(norm_factors.sqrt())\n",
    "\n",
    "    def normalize_(self, *, _efficient_mode: bool = True):\n",
    "        \"\"\"\n",
    "        Normalize the MPS in-place.\n",
    "        \"\"\"\n",
    "        if _efficient_mode and self.center is not None:\n",
    "            self._mps[self.center] /= self.norm()\n",
    "        else:\n",
    "            norm_factors = 1 / self.norm_factors().sqrt()\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] *= norm_factors[i]\n",
    "\n",
    "    def inner_product(self, other: \"MPS\", return_product_factors: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the inner product of two MPS. These two MPS must have the same length.\n",
    "        \"\"\"\n",
    "        assert isinstance(other, MPS), \"other must be a MPS\"\n",
    "        assert self.length == other.length, \"length of two MPS must be the same\"\n",
    "        product_factors = calc_inner_product(self._mps, other._mps)\n",
    "        if return_product_factors:\n",
    "            return product_factors\n",
    "        else:\n",
    "            return torch.prod(product_factors)\n",
    "\n",
    "    def check_orthogonality(\n",
    "        self, *, check_mode: Literal[\"print\", \"assert\"] = \"print\", tolerance: float = 1e-6\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Check the orthogonality of the MPS.\n",
    "        \"\"\"\n",
    "        assert check_mode.lower() in [\"print\", \"assert\"], (\n",
    "            \"check_mode must be either 'print' or 'assert'\"\n",
    "        )\n",
    "        print_mode = check_mode.lower() == \"print\"\n",
    "        if self.center is None:\n",
    "            print(\"center is None, so no orthogonality check can be performed\")\n",
    "        else:\n",
    "            identity = torch.eye(\n",
    "                2, dtype=self._dtype, device=self._device\n",
    "            )  # cache for the identity matrix\n",
    "            for i in range(self.length):\n",
    "                if i == self.center:\n",
    "                    if print_mode:\n",
    "                        print(f\"Local Tensor {i}: Center\")\n",
    "                else:\n",
    "                    local_tensor = self._mps[i]\n",
    "                    if i < self.center:\n",
    "                        product = torch.einsum(\"abc,abd->cd\", local_tensor.conj(), local_tensor)\n",
    "                    else:\n",
    "                        product = torch.einsum(\"xab,yab->xy\", local_tensor, local_tensor.conj())\n",
    "\n",
    "                    assert product.shape[0] == product.shape[1]\n",
    "\n",
    "                    if identity.shape[0] != product.shape[0]:\n",
    "                        identity = torch.eye(\n",
    "                            product.shape[0], dtype=self._dtype, device=self._device\n",
    "                        )\n",
    "\n",
    "                    diff_norm = (product - identity).norm(p=1).item()\n",
    "\n",
    "                    if print_mode:\n",
    "                        print(f\"Local Tensor {i}: {diff_norm}\")\n",
    "                    else:\n",
    "                        assert diff_norm < tolerance, (\n",
    "                            f\"Local Tensor {i} is not orthogonal, {diff_norm=}\"\n",
    "                        )\n",
    "\n",
    "    def to_(self, dtype: torch.dtype | None = None, device: torch.device | None = None) -> \"MPS\":\n",
    "        if dtype is not None and self._dtype != dtype:\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = self._mps[i].to(dtype=dtype)\n",
    "            self._dtype = dtype\n",
    "        if device is not None and self._device != device:\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = self._mps[i].to(device=device)\n",
    "            self._device = device\n",
    "        return self\n",
    "\n",
    "    def one_body_reduced_density_matrix(\n",
    "        self, *, idx: int, inplace_mutation: bool = False\n",
    "    ) -> torch.Tensor:\n",
    "        assert 0 <= idx < self.length, \"idx must be in [0, length - 1]\"\n",
    "        if self.center is None:  # TODO: optimize this branch\n",
    "            # maybe we can just use einsum here, need some benchmarking\n",
    "            if inplace_mutation:\n",
    "                self.center_orthogonalization_(idx, \"qr\")\n",
    "                return self.one_body_reduced_density_matrix(idx=idx)\n",
    "            else:\n",
    "                # do center orthogonalization out of place\n",
    "                local_tensors = self.local_tensors\n",
    "                length = len(local_tensors)\n",
    "                center = idx\n",
    "                mode = \"qr\"\n",
    "                local_tensors = orthogonalize_arange(local_tensors, 0, center, mode)\n",
    "                local_tensors = orthogonalize_arange(local_tensors, length - 1, center, mode)\n",
    "                center_tensor = local_tensors[center]\n",
    "        else:\n",
    "            if self.center == idx:\n",
    "                center_tensor = self.center_tensor\n",
    "            else:  # TODO: optimize this branch\n",
    "                if inplace_mutation:\n",
    "                    self.center_orthogonalization_(idx, \"qr\")\n",
    "                    return self.one_body_reduced_density_matrix(idx=idx)\n",
    "                else:\n",
    "                    # moving center out of place\n",
    "                    local_tensors = self.local_tensors\n",
    "                    new_center = idx\n",
    "                    local_tensors = orthogonalize_arange(\n",
    "                        local_tensors, self.center, new_center, mode=\"qr\"\n",
    "                    )\n",
    "                    center_tensor = local_tensors[new_center]\n",
    "\n",
    "        return einsum(\n",
    "            center_tensor,\n",
    "            center_tensor.conj(),\n",
    "            \"left mid right, left mid_conj right -> mid mid_conj\",\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def center_tensor(self) -> torch.Tensor | None:\n",
    "        if self.center is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self._mps[self.center]\n",
    "\n",
    "    @property\n",
    "    def local_tensors(self) -> List[torch.Tensor]:\n",
    "        return [i for i in self._mps]\n",
    "\n",
    "    @property\n",
    "    def length(self) -> int:\n",
    "        return self._length\n",
    "\n",
    "    @property\n",
    "    def physical_dim(self) -> int:\n",
    "        return self._physical_dim\n",
    "\n",
    "    @property\n",
    "    def virtual_dim(self) -> int:\n",
    "        return self._virtual_dim\n",
    "\n",
    "    @property\n",
    "    def mps_type(self) -> MPSType:\n",
    "        return self._mps_type\n",
    "\n",
    "    @property\n",
    "    def center(self) -> int | None:\n",
    "        return self._center\n",
    "\n",
    "    @staticmethod\n",
    "    def from_state_tensor(\n",
    "        state_tensor: torch.Tensor, max_rank: int | None = None, use_svd: bool = False\n",
    "    ) -> \"MPS\":\n",
    "        local_tensors, _ = tt_decomposition(state_tensor, max_rank=max_rank, use_svd=use_svd)\n",
    "        mps = MPS(mps_tensors=local_tensors)\n",
    "        mps._center = len(local_tensors) - 1\n",
    "        return mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Central Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "\n",
    "para = {\"length\": length, \"d\": physical_dim, \"chi\": virtual_dim, \"dtype\": dtype}\n",
    "\n",
    "for i in range(length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    mps = MPS(mps_tensors=mps_tensors, requires_grad=False)\n",
    "    global_tensor = mps.global_tensor()\n",
    "    psi.center_orthogonalization(i, \"svd\")\n",
    "    mps.center_orthogonalization_(i, \"svd\")\n",
    "    new_global_tensor = mps.global_tensor()\n",
    "    assert torch.allclose(global_tensor, new_global_tensor)\n",
    "    mps.check_orthogonality(check_mode=\"assert\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    orthogonalized_mps_tensors = mps.local_tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    mps = MPS(mps_tensors=mps_tensors, requires_grad=False)\n",
    "    psi.center_orthogonalization(i, \"svd\", 2)\n",
    "    mps.center_orthogonalization_(i, \"svd\", 2)\n",
    "    mps.check_orthogonality(check_mode=\"assert\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    orthogonalized_mps_tensors = mps.local_tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Norm of MPS = Norm of Center of MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for i in range(length):\n",
    "    mps = MPS(\n",
    "        length=length,\n",
    "        physical_dim=physical_dim,\n",
    "        virtual_dim=virtual_dim,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "        mps_type=MPSType.Open,\n",
    "        requires_grad=False,\n",
    "    )\n",
    "    mps.center_orthogonalization_(i, \"svd\")\n",
    "    global_tensor = mps.global_tensor()\n",
    "    norm_ref = global_tensor.norm()\n",
    "    norm_mps_efficient = mps.norm(_efficient_mode=True)\n",
    "    norm_mps_normal = mps.norm(_efficient_mode=False)\n",
    "    assert torch.allclose(norm_mps_efficient, norm_ref)\n",
    "    assert torch.allclose(norm_mps_normal, norm_ref)\n",
    "\n",
    "for i in range(length):\n",
    "    mps = MPS(\n",
    "        length=length,\n",
    "        physical_dim=physical_dim,\n",
    "        virtual_dim=virtual_dim,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "        mps_type=MPSType.Open,\n",
    "        requires_grad=False,\n",
    "    )\n",
    "    mps.center_orthogonalization_(i, \"svd\")\n",
    "    mps.normalize_(_efficient_mode=True)\n",
    "    global_tensor = mps.global_tensor()\n",
    "    norm = global_tensor.norm()\n",
    "    assert torch.allclose(norm, torch.ones_like(norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Center Tensor Singular Spetrum Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "device = torch.device(\"cpu\")\n",
    "center = 3\n",
    "\n",
    "mps = MPS(\n",
    "    length=length,\n",
    "    physical_dim=physical_dim,\n",
    "    virtual_dim=virtual_dim,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    "    mps_type=MPSType.Open,\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "mps.center_orthogonalization_(center, \"svd\")\n",
    "\n",
    "global_tensor = mps.global_tensor()\n",
    "center_tensor = mps.center_tensor\n",
    "\n",
    "center_tensor_mat_left = center_tensor.view(center_tensor.shape[0], -1)\n",
    "left_singular_values = torch.linalg.svdvals(center_tensor_mat_left)\n",
    "center_tensor_mat_right = center_tensor.view(-1, center_tensor.shape[-1])\n",
    "right_singular_values = torch.linalg.svdvals(center_tensor_mat_right)\n",
    "\n",
    "left_shape = global_tensor.shape[:center]\n",
    "left_dim = torch.prod(torch.tensor(left_shape))\n",
    "right_shape = global_tensor.shape[center + 1 :]\n",
    "right_dim = torch.prod(torch.tensor(right_shape))\n",
    "\n",
    "global_tensor_mat_left = global_tensor.view(left_dim, -1)\n",
    "global_tensor_mat_right = global_tensor.view(-1, right_dim)\n",
    "\n",
    "ref_left_singular_values = torch.linalg.svdvals(global_tensor_mat_left)\n",
    "ref_right_singular_values = torch.linalg.svdvals(global_tensor_mat_right)\n",
    "\n",
    "# add zero padding to the left and right singular values, because the references have more singular values due to numerical errors\n",
    "left_singular_values = torch.cat(\n",
    "    [\n",
    "        left_singular_values,\n",
    "        torch.zeros(ref_left_singular_values.shape[0] - left_singular_values.shape[0]),\n",
    "    ]\n",
    ")\n",
    "right_singular_values = torch.cat(\n",
    "    [\n",
    "        right_singular_values,\n",
    "        torch.zeros(ref_right_singular_values.shape[0] - right_singular_values.shape[0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "assert torch.allclose(left_singular_values, ref_left_singular_values)\n",
    "assert torch.allclose(right_singular_values, ref_right_singular_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Reduced Density Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_network.quantum_state.functional import calc_reduced_density_matrix\n",
    "from Library.QuantumState import TensorPureState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for center in range(length):\n",
    "    for i in range(length):\n",
    "        for inplace_mutation in [True, False]:\n",
    "            psi = MPS_basic(\n",
    "                para={\"length\": length, \"d\": physical_dim, \"chi\": virtual_dim, \"dtype\": dtype}\n",
    "            )\n",
    "            mps_tensors = deepcopy(psi.tensors)\n",
    "            mps = MPS(mps_tensors=mps_tensors, requires_grad=False)\n",
    "            mps.center_orthogonalization_(center, \"qr\")\n",
    "            psi.center_orthogonalization(center, \"svd\")\n",
    "\n",
    "            global_tensor = mps.global_tensor()\n",
    "            global_tensor_ref = psi.full_tensor()\n",
    "            assert torch.allclose(global_tensor_ref, global_tensor)\n",
    "\n",
    "            tensor_pure_state = TensorPureState(tensor=global_tensor)\n",
    "\n",
    "            reduced_density_matrix_tps = tensor_pure_state.reduced_density_matrix(i)\n",
    "            reduced_density_matrix_psi = psi.one_body_RDM(i)\n",
    "            reduced_density_matrix_mps = mps.one_body_reduced_density_matrix(\n",
    "                idx=i, inplace_mutation=inplace_mutation\n",
    "            )\n",
    "            reduced_density_matrix_mine = calc_reduced_density_matrix(global_tensor, i)\n",
    "\n",
    "            assert torch.allclose(reduced_density_matrix_mps, reduced_density_matrix_mine)\n",
    "            assert torch.allclose(reduced_density_matrix_tps, reduced_density_matrix_mine)\n",
    "\n",
    "            normalized_reduced_density_matrix = reduced_density_matrix_mps / torch.trace(\n",
    "                reduced_density_matrix_mps\n",
    "            )\n",
    "            # transpose here because the reference code has a minor bug\n",
    "            assert torch.allclose(reduced_density_matrix_psi.T, normalized_reduced_density_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psi.center: -1\n",
      "psi.center: 3\n"
     ]
    }
   ],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "device = torch.device(\"cpu\")\n",
    "center = 3\n",
    "\n",
    "para = {\"length\": length, \"d\": physical_dim, \"chi\": virtual_dim, \"dtype\": dtype}\n",
    "\n",
    "psi = MPS_basic(para=para)\n",
    "print(f\"psi.center: {psi.center}\")\n",
    "reduced_density_matrix_psi_before = psi.one_body_RDM(center)\n",
    "psi.center_orthogonalization(center, \"svd\")\n",
    "print(f\"psi.center: {psi.center}\")\n",
    "reduced_density_matrix_psi_after = psi.one_body_RDM(center)\n",
    "\n",
    "\n",
    "# FIXME: this will fail. fix the bug in the reference code\n",
    "# assert torch.allclose(reduced_density_matrix_psi_before, reduced_density_matrix_psi_after), f\"reduced_density_matrix_psi_before: {reduced_density_matrix_psi_before}\\n\\nreduced_density_matrix_psi_after: {reduced_density_matrix_psi_after}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
