{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2: 矩阵乘积态的中心正交形式（Central Orthogonal Form）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp mps.modules\n",
    "# |export\n",
    "import torch\n",
    "from typing import List, Tuple, Literal\n",
    "from tensor_network.mps.functional import gen_random_mps_tensors, MPSType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalization One Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export mps.functional\n",
    "from typing import Literal, Tuple\n",
    "\n",
    "\n",
    "def orthogonalize_left2right_step(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    local_tensor_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_locals: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    One step of orthogonalization from left to right, which will make the local tensor isometric and the right one to it transformed.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        local_tensor_idx: int, the index of the local tensor to be orthogonalized.\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_locals: bool, whether to return the local tensors. If True, only the local and the right one will be returned.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after one step of orthogonalization from left to right.\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 0 <= local_tensor_idx < length - 1, \"local_tensor_idx must be in [0, length - 2]\"\n",
    "    mode = mode.lower()\n",
    "    assert mode in [\"svd\", \"qr\"], \"mode must be either 'svd' or 'qr'\"\n",
    "    local_tensor = mps_tensors[local_tensor_idx]\n",
    "    shape = local_tensor.shape  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    if truncate_dim is not None:\n",
    "        virtual_dim = shape[2]\n",
    "        assert virtual_dim > truncate_dim > 0, (\n",
    "            \"truncate_dim must be positive and less than virtual_dim\"\n",
    "        )\n",
    "        assert mode == \"svd\", \"mode must be 'svd' when truncate_dim is provided\"\n",
    "        need_truncate = True\n",
    "    else:\n",
    "        need_truncate = False\n",
    "\n",
    "    view_matrix = local_tensor.view(-1, shape[2])\n",
    "\n",
    "    if mode == \"svd\":\n",
    "        u, lm, v = torch.linalg.svd(view_matrix, full_matrices=False)\n",
    "        if need_truncate:\n",
    "            u = u[:, :truncate_dim]\n",
    "            lm = lm[:truncate_dim]  # (truncate_dim)\n",
    "            v = v[:truncate_dim, :]  # (truncate_dim, virtual_dim)\n",
    "            r = lm.unsqueeze(1) * v  # (truncate_dim, virtual_dim)\n",
    "        else:\n",
    "            r = lm.unsqueeze(1) * v  # (virtual_dim, virtual_dim)\n",
    "    else:\n",
    "        u, r = torch.linalg.qr(view_matrix)\n",
    "\n",
    "    new_local_tensor = u.reshape(\n",
    "        shape[0], shape[1], -1\n",
    "    )  # (virtual_dim, physical_dim, virtual_dim or truncate_dim)\n",
    "    local_tensor_right = mps_tensors[\n",
    "        local_tensor_idx + 1\n",
    "    ]  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    new_local_tensor_right = torch.einsum(\"ab,bcd->acd\", r, local_tensor_right)\n",
    "    if return_locals:\n",
    "        return new_local_tensor, new_local_tensor_right\n",
    "    else:\n",
    "        return (\n",
    "            mps_tensors[:local_tensor_idx]\n",
    "            + [new_local_tensor, new_local_tensor_right]\n",
    "            + mps_tensors[local_tensor_idx + 2 :]\n",
    "        )\n",
    "\n",
    "\n",
    "def orthogonalize_right2left_step(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    local_tensor_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_locals: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    One step of orthogonalization from right to left, which will make the local tensor isometric and the left one to it transformed.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        local_tensor_idx: int, the index of the local tensor to be orthogonalized.\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_locals: bool, whether to return the local tensors. If True, only the local and the left one will be returned.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after one step of orthogonalization from right to left.\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 1 <= local_tensor_idx < length, \"local_tensor_idx must be in [1, length - 1]\"\n",
    "    mode = mode.lower()\n",
    "    assert mode in [\"svd\", \"qr\"], \"mode must be either 'svd' or 'qr'\"\n",
    "    local_tensor = mps_tensors[local_tensor_idx]\n",
    "    shape = local_tensor.shape  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    if truncate_dim is not None:\n",
    "        virtual_dim = shape[0]\n",
    "        assert virtual_dim > truncate_dim > 0, (\n",
    "            \"truncate_dim must be positive and less than virtual_dim\"\n",
    "        )\n",
    "        assert mode == \"svd\", \"mode must be 'svd' when truncate_dim is provided\"\n",
    "        need_truncate = True\n",
    "    else:\n",
    "        need_truncate = False\n",
    "\n",
    "    view_matrix = local_tensor.view(\n",
    "        shape[0], -1\n",
    "    ).t()  # (virtual_dim, virtual_dim * physical_dim) -> (virtual_dim * physical_dim, virtual_dim)\n",
    "    if mode == \"svd\":\n",
    "        u, lm, v = torch.linalg.svd(view_matrix, full_matrices=False)\n",
    "        if need_truncate:\n",
    "            u = u[:, :truncate_dim]\n",
    "            lm = lm[:truncate_dim]  # (truncate_dim)\n",
    "            v = v[:truncate_dim, :]  # (truncate_dim, virtual_dim)\n",
    "            r = lm.unsqueeze(1) * v  # (truncate_dim, virtual_dim)\n",
    "        else:\n",
    "            r = lm.unsqueeze(1) * v  # (virtual_dim, virtual_dim)\n",
    "    else:\n",
    "        u, r = torch.linalg.qr(view_matrix)\n",
    "\n",
    "    new_local_tensor = u.t().reshape(\n",
    "        -1, shape[1], shape[2]\n",
    "    )  # (virtual_dim or truncate_dim, physical_dim, virtual_dim)\n",
    "    local_tensor_left = mps_tensors[\n",
    "        local_tensor_idx - 1\n",
    "    ]  # (virtual_dim, physical_dim, virtual_dim)\n",
    "    new_local_tensor_left = torch.einsum(\"abc,dc->abd\", local_tensor_left, r)\n",
    "    if return_locals:\n",
    "        return new_local_tensor_left, new_local_tensor\n",
    "    else:\n",
    "        return (\n",
    "            mps_tensors[: local_tensor_idx - 1]\n",
    "            + [new_local_tensor_left, new_local_tensor]\n",
    "            + mps_tensors[local_tensor_idx + 1 :]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From setup_ref_code_import:\n",
      "  Added reference_code_path='/Users/zhiqiu/offline_code/personal/tensor_network/reference_code' to sys.path.\n",
      "  You can import the reference code now.\n"
     ]
    }
   ],
   "source": [
    "from tensor_network import setup_ref_code_import\n",
    "from Library.MatrixProductState import MPS_basic\n",
    "from copy import deepcopy\n",
    "\n",
    "length = 8\n",
    "\n",
    "para = {\"length\": length, \"d\": 3, \"chi\": 4, \"dtype\": torch.complex128}\n",
    "\n",
    "for i in range(length - 1):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_left2right(i, \"svd\")\n",
    "    orthogonalized_mps_tensors = orthogonalize_left2right_step(mps_tensors, i, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(length - 1):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_left2right(i, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors = orthogonalize_left2right_step(\n",
    "        mps_tensors, i, \"svd\", truncate_dim=2\n",
    "    )\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "\n",
    "for i in range(1, length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_right2left(i, \"svd\")\n",
    "    orthogonalized_mps_tensors = orthogonalize_right2left_step(mps_tensors, i, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(1, length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_right2left(i, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors = orthogonalize_right2left_step(\n",
    "        mps_tensors, i, \"svd\", truncate_dim=2\n",
    "    )\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export mps.functional\n",
    "def orthogonalize_arange(\n",
    "    mps_tensors: List[torch.Tensor],\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    mode: Literal[\"svd\", \"qr\"],\n",
    "    truncate_dim: int | None = None,\n",
    "    return_changed: bool = False,\n",
    ") -> List[torch.Tensor] | Tuple[List[torch.Tensor], List[int]]:\n",
    "    \"\"\"\n",
    "    Perform orthogonalization on the range of tensors.\n",
    "\n",
    "    Args:\n",
    "        mps_tensors: List[torch.Tensor], MPS tensors\n",
    "        start_idx: int, the start index of the range\n",
    "        end_idx: int, the end index of the range\n",
    "        mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization\n",
    "        truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        return_changed: bool, whether to return the changed tensors. If True, changed tensors' indices will be returned as well.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor], the list of tensors after orthogonalization\n",
    "    \"\"\"\n",
    "    length = len(mps_tensors)\n",
    "    assert length > 1, \"mps_tensors must have at least 2 tensors\"\n",
    "    assert 0 <= start_idx < length and 0 <= end_idx < length, (\n",
    "        \"start_idx and end_idx must be in [0, length - 1]\"\n",
    "    )\n",
    "    mps_tensors = [m for m in mps_tensors]\n",
    "    changed_indices = set()\n",
    "    if start_idx < end_idx:\n",
    "        for idx in range(start_idx, end_idx, 1):\n",
    "            local, local_right = orthogonalize_left2right_step(\n",
    "                mps_tensors, idx, mode, truncate_dim, return_locals=True\n",
    "            )\n",
    "            mps_tensors[idx] = local\n",
    "            mps_tensors[idx + 1] = local_right\n",
    "            changed_indices.add(idx)\n",
    "            changed_indices.add(idx + 1)\n",
    "    elif start_idx > end_idx:\n",
    "        for idx in range(start_idx, end_idx, -1):\n",
    "            local_left, local = orthogonalize_right2left_step(\n",
    "                mps_tensors, idx, mode, truncate_dim, return_locals=True\n",
    "            )\n",
    "            mps_tensors[idx - 1] = local_left\n",
    "            mps_tensors[idx] = local\n",
    "            changed_indices.add(idx - 1)\n",
    "            changed_indices.add(idx)\n",
    "    else:\n",
    "        # do nothing when start_idx == end_idx\n",
    "        pass\n",
    "\n",
    "    if return_changed:\n",
    "        changed_indices = list(changed_indices)\n",
    "        changed_indices.sort()\n",
    "        return mps_tensors, changed_indices\n",
    "    else:\n",
    "        return mps_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "num_trials = 20\n",
    "\n",
    "length = 8\n",
    "\n",
    "para = {\"length\": length, \"d\": 3, \"chi\": 4, \"dtype\": torch.complex128}\n",
    "\n",
    "i = 0\n",
    "while i < num_trials:\n",
    "    start_idx = randint(0, length - 1)\n",
    "    end_idx = randint(0, length - 1)\n",
    "    if start_idx == end_idx:\n",
    "        continue\n",
    "    i += 1\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_n1_n2(start_idx, end_idx, \"svd\", -1, False)\n",
    "    orthogonalized_mps_tensors = orthogonalize_arange(mps_tensors, start_idx, end_idx, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "\n",
    "# with truncate_dim = 2\n",
    "i = 0\n",
    "while i < num_trials:\n",
    "    start_idx = randint(0, length - 1)\n",
    "    end_idx = randint(0, length - 1)\n",
    "    if start_idx == end_idx:\n",
    "        continue\n",
    "    i += 1\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    psi.orthogonalize_n1_n2(start_idx, end_idx, \"svd\", 2, False)\n",
    "    orthogonalized_mps_tensors = orthogonalize_arange(mps_tensors, start_idx, end_idx, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPS Module and Center Orthogonalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from tensor_network.mps.functional import (\n",
    "    orthogonalize_arange,\n",
    "    calc_global_tensor_by_tensordot,\n",
    "    calculate_mps_norm_factors,\n",
    "    calc_inner_product,\n",
    ")\n",
    "import sys\n",
    "\n",
    "\n",
    "class MPS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        mps_tensors: List[torch.Tensor] | None = None,\n",
    "        length: int | None = None,\n",
    "        physical_dim: int | None = None,\n",
    "        virtual_dim: int | None = None,\n",
    "        mps_type: MPSType | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "        device: torch.device | None = None,\n",
    "        requires_grad: bool | None = None,\n",
    "    ) -> None:\n",
    "        if mps_tensors is None:\n",
    "            assert (\n",
    "                length is not None\n",
    "                and physical_dim is not None\n",
    "                and virtual_dim is not None\n",
    "                and mps_type is not None\n",
    "                and dtype is not None\n",
    "                and device is not None\n",
    "                and requires_grad is not None\n",
    "            ), \"mps_tensors is None, so all arguments must be provided\"\n",
    "            mps_tensors = gen_random_mps_tensors(\n",
    "                length, physical_dim, virtual_dim, mps_type, dtype, device\n",
    "            )\n",
    "            for i in range(len(mps_tensors)):\n",
    "                mps_tensors[i].requires_grad = requires_grad\n",
    "            self._length: int = length\n",
    "            self._physical_dim: int = physical_dim\n",
    "            self._virtual_dim: int = virtual_dim\n",
    "            self._mps_type: MPSType = mps_type\n",
    "            self._dtype: torch.dtype = dtype\n",
    "            self._device: torch.device = device\n",
    "        else:\n",
    "            # TODO: checking whether the mps_tensors is valid, not emergent\n",
    "            self._length: int = len(mps_tensors)\n",
    "            self._physical_dim: int = mps_tensors[0].shape[1]\n",
    "            self._virtual_dim: int = mps_tensors[0].shape[2]\n",
    "            self._mps_type: MPSType = (\n",
    "                MPSType.Open if mps_tensors[0].shape[0] == 1 else MPSType.Periodic\n",
    "            )\n",
    "            self._dtype: torch.dtype = mps_tensors[0].dtype\n",
    "            self._device: torch.device = mps_tensors[0].device\n",
    "            requires_grad = mps_tensors[0].requires_grad if requires_grad is None else requires_grad\n",
    "\n",
    "        self._requires_grad: bool = requires_grad\n",
    "        self._mps: List[torch.Tensor] = mps_tensors\n",
    "        self._center: int | None = None\n",
    "\n",
    "    def center_orthogonalization_(\n",
    "        self, center: int, mode: Literal[\"svd\", \"qr\"], truncate_dim: int | None = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform center orthogonalization on the MPS. This is an in-place operation.\n",
    "\n",
    "        Args:\n",
    "            center: int, the center of the MPS.\n",
    "            mode: Literal[\"svd\", \"qr\"], the mode of orthogonalization.\n",
    "            truncate_dim: int | None, the dimension to be truncated. If None, no truncation will be performed.\n",
    "        \"\"\"\n",
    "        assert -self.length <= center < self.length, \"center out of range\"\n",
    "        if center < 0:\n",
    "            center = self.length + center\n",
    "        if self._center is None:\n",
    "            new_local_tensors = orthogonalize_arange(self._mps, 0, center, mode, truncate_dim)\n",
    "            new_local_tensors = orthogonalize_arange(\n",
    "                new_local_tensors, self.length - 1, center, mode, truncate_dim\n",
    "            )\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = new_local_tensors[i]\n",
    "        elif self.center != center:\n",
    "            new_local_tensors, changed_indices = orthogonalize_arange(\n",
    "                self._mps, self.center, center, mode, truncate_dim, return_changed=True\n",
    "            )\n",
    "            for changed_idx in changed_indices:\n",
    "                self._mps[changed_idx] = new_local_tensors[changed_idx]\n",
    "        else:\n",
    "            # when self.center == center\n",
    "            pass\n",
    "        self._center = center\n",
    "\n",
    "    def force_set_local_tensor_(self, i: int, value: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Force set the local tensor at index i to the given value with checking the shape and dtype.\n",
    "\n",
    "        Args:\n",
    "            i: int, the index of the local tensor to be set.\n",
    "            value: torch.Tensor, the value to be set.\n",
    "        \"\"\"\n",
    "        value = value.to(dtype=self._dtype, device=self._device)\n",
    "        value.requires_grad = self._requires_grad\n",
    "        self._mps[i] = value\n",
    "\n",
    "    def __getitem__(self, i: int) -> torch.Tensor:\n",
    "        return self._mps[i]\n",
    "\n",
    "    def __setitem__(self, i: int, value: torch.Tensor):\n",
    "        local_tensor_shape = self[i].shape\n",
    "        local_tensor_dtype = self[i].dtype\n",
    "        assert value.shape == local_tensor_shape, (\n",
    "            f\"value shape must match local tensor shape {local_tensor_shape}, but got {value.shape}\"\n",
    "        )\n",
    "        assert value.dtype == local_tensor_dtype, (\n",
    "            f\"value dtype must match local tensor dtype {local_tensor_dtype}, but got {value.dtype}\"\n",
    "        )\n",
    "        self.force_set_local_tensor_(i, value)\n",
    "\n",
    "    def global_tensor(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the global tensor of the MPS.\n",
    "        \"\"\"\n",
    "        # use tensordot to contract the mps tensors, because it's faster than calc_global_tensor_by_contract\n",
    "        if self.length > 15:\n",
    "            print(\n",
    "                \"Warning: Calculating global tensor of MPS with length > 15, this may up all the memory\",\n",
    "                file=sys.stderr,\n",
    "            )\n",
    "        return calc_global_tensor_by_tensordot(self._mps)\n",
    "\n",
    "    def norm_factors(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the norm factors of the MPS.\n",
    "        \"\"\"\n",
    "        return calculate_mps_norm_factors(self._mps)\n",
    "\n",
    "    def norm(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the norm of the MPS.\n",
    "        \"\"\"\n",
    "        norm_factors = self.norm_factors()\n",
    "        # use sqrt inside the product to avoid overflow\n",
    "        return torch.prod(norm_factors.sqrt())\n",
    "\n",
    "    def normalize_(self):\n",
    "        \"\"\"\n",
    "        Normalize the MPS in-place.\n",
    "        \"\"\"\n",
    "        norm_factors = 1 / self.norm_factors().sqrt()\n",
    "        for i in range(self.length):\n",
    "            self._mps[i] *= norm_factors[i]\n",
    "\n",
    "    def inner_product(self, other: \"MPS\", return_product_factors: bool = False) -> torch.Tensor:\n",
    "        assert isinstance(other, MPS), \"other must be a MPS\"\n",
    "        assert self.length == other.length, \"length of two MPS must be the same\"\n",
    "        product_factors = calc_inner_product(self._mps, other._mps)\n",
    "        if return_product_factors:\n",
    "            return product_factors\n",
    "        else:\n",
    "            return torch.prod(product_factors)\n",
    "\n",
    "    def to_(self, dtype: torch.dtype | None = None, device: torch.device | None = None) -> \"MPS\":\n",
    "        if dtype is not None and self._dtype != dtype:\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = self._mps[i].to(dtype=dtype)\n",
    "            self._dtype = dtype\n",
    "        if device is not None and self._device != device:\n",
    "            for i in range(self.length):\n",
    "                self._mps[i] = self._mps[i].to(device=device)\n",
    "            self._device = device\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def local_tensors(self) -> List[torch.Tensor]:\n",
    "        return [i for i in self._mps]\n",
    "\n",
    "    @property\n",
    "    def length(self) -> int:\n",
    "        return self._length\n",
    "\n",
    "    @property\n",
    "    def physical_dim(self) -> int:\n",
    "        return self._physical_dim\n",
    "\n",
    "    @property\n",
    "    def virtual_dim(self) -> int:\n",
    "        return self._virtual_dim\n",
    "\n",
    "    @property\n",
    "    def mps_type(self) -> MPSType:\n",
    "        return self._mps_type\n",
    "\n",
    "    @property\n",
    "    def center(self) -> int | None:\n",
    "        return self._center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8\n",
    "physical_dim = 3\n",
    "virtual_dim = 4\n",
    "dtype = torch.complex128\n",
    "\n",
    "para = {\"length\": length, \"d\": physical_dim, \"chi\": virtual_dim, \"dtype\": dtype}\n",
    "\n",
    "for i in range(length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    mps = MPS(mps_tensors=mps_tensors, requires_grad=False)\n",
    "    psi.center_orthogonalization(i, \"svd\")\n",
    "    mps.center_orthogonalization_(i, \"svd\")\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    orthogonalized_mps_tensors = mps.local_tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])\n",
    "\n",
    "# with truncate_dim\n",
    "for i in range(length):\n",
    "    psi = MPS_basic(para=para)\n",
    "    mps_tensors = deepcopy(psi.tensors)\n",
    "    mps = MPS(mps_tensors=mps_tensors, requires_grad=False)\n",
    "    psi.center_orthogonalization(i, \"svd\", 2)\n",
    "    mps.center_orthogonalization_(i, \"svd\", 2)\n",
    "    orthogonalized_mps_tensors_ref = psi.tensors\n",
    "    orthogonalized_mps_tensors = mps.local_tensors\n",
    "    assert len(orthogonalized_mps_tensors) == len(orthogonalized_mps_tensors_ref)\n",
    "    for j in range(len(orthogonalized_mps_tensors)):\n",
    "        assert torch.allclose(orthogonalized_mps_tensors[j], orthogonalized_mps_tensors_ref[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
